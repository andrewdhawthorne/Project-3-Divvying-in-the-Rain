{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient, UpdateOne\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from config import api_key_zip, api_key_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents in Top10StartStationsCopy:\n",
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 71269, 'latitude': 41.880958, 'longitude': -87.616743}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 39251, 'latitude': 41.867888, 'longitude': -87.623041}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 37698, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 37208, 'latitude': 41.869265218438194, 'longitude': -87.67373085021973}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34508, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Millennium Park', 'count': 32849, 'latitude': 41.8810317, 'longitude': -87.62408432}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32560, 'latitude': 41.920771, 'longitude': -87.663712}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 31614, 'latitude': 41.893992, 'longitude': -87.629318}\n",
      "{'_id': 'Theater on the Lake', 'count': 31283, 'latitude': 41.926277, 'longitude': -87.630834}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28978, 'latitude': 41.893992, 'longitude': -87.629318}\n",
      "\n",
      "Documents in Top10EndStationsCopy:\n",
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 72540, 'latitude': 41.892278, 'longitude': -87.612043}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 40563, 'latitude': 41.911722, 'longitude': -87.626804}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 38500, 'latitude': 41.880958, 'longitude': -87.616743}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 38279, 'latitude': 41.90096039, 'longitude': -87.62377664}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34688, 'latitude': 41.912133, 'longitude': -87.634656}\n",
      "{'_id': 'Millennium Park', 'count': 33705, 'latitude': 41.8810317, 'longitude': -87.62408432}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32227, 'latitude': 41.902973, 'longitude': -87.63128}\n",
      "{'_id': 'Theater on the Lake', 'count': 31672, 'latitude': 41.926277, 'longitude': -87.630834}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 30450, 'latitude': 41.88917683258, 'longitude': -87.6385057718}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28346, 'latitude': 41.903222, 'longitude': -87.634324}\n"
     ]
    }
   ],
   "source": [
    "# Create a new database to hold copies of collections as to not interfere with data in the original collections\n",
    "# MongoDB connection URI\n",
    "mongo_uri = \"mongodb://localhost:27017/\"\n",
    "mongo = MongoClient(mongo_uri)\n",
    "\n",
    "# Connect to the original database\n",
    "db = mongo.chicago_bikes\n",
    "\n",
    "# Connect to the collections in the original database\n",
    "start_stations_original = db['Top10StartStations']\n",
    "end_stations_original = db['Top10EndStations']\n",
    "\n",
    "# Connect to the new database\n",
    "db2 = mongo[\"chicago_bikes_copy\"]\n",
    "\n",
    "# Specify the names of the new collections\n",
    "new_start_collection_name = 'Top10StartStationsCopy'\n",
    "new_end_collection_name = 'Top10EndStationsCopy'\n",
    "\n",
    "# Drop existing collections with the same names in the new database (if needed)\n",
    "db2[new_start_collection_name].drop()\n",
    "db2[new_end_collection_name].drop()\n",
    "\n",
    "# Create new collections in the new database\n",
    "db2[new_start_collection_name].insert_many(start_stations_original.find())\n",
    "db2[new_end_collection_name].insert_many(end_stations_original.find())\n",
    "\n",
    "# Print each document in the new start stations collection to verify the data transfer\n",
    "print(f\"Documents in {new_start_collection_name}:\")\n",
    "for doc in db2[new_start_collection_name].find():\n",
    "    print(doc)\n",
    "\n",
    "# Print each document in the new end stations collection to verify the data transfer\n",
    "print(f\"\\nDocuments in {new_end_collection_name}:\")\n",
    "for doc in db2[new_end_collection_name].find():\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Stations Coordinates: [(41.880958, -87.616743), (41.867888, -87.623041), (41.897448, -87.628722), (41.869265218438194, -87.67373085021973), (41.897448, -87.628722), (41.8810317, -87.62408432), (41.920771, -87.663712), (41.893992, -87.629318), (41.926277, -87.630834), (41.893992, -87.629318)]\n",
      "End Stations Coordinates: [(41.892278, -87.612043), (41.911722, -87.626804), (41.880958, -87.616743), (41.90096039, -87.62377664), (41.912133, -87.634656), (41.8810317, -87.62408432), (41.902973, -87.63128), (41.926277, -87.630834), (41.88917683258, -87.6385057718), (41.903222, -87.634324)]\n"
     ]
    }
   ],
   "source": [
    "# Get the latitude and longitude from the top 10 stations and top 10 end stations\n",
    "\n",
    "# Connect to collections\n",
    "new_start_stations_collection = db2.Top10StartStationsCopy\n",
    "new_end_stations_collection = db2.Top10EndStationsCopy\n",
    "\n",
    "# Fetch the top 10 start and end stations\n",
    "top_start_stations = new_start_stations_collection.find({}, {'_id': 0, 'latitude': 1, 'longitude': 1})\n",
    "top_end_stations = new_end_stations_collection.find({}, {'_id': 0, 'latitude': 1, 'longitude': 1})\n",
    "\n",
    "# Function to iterate over the cursor and extract lat and long data\n",
    "def extract_lat_long(cursor):\n",
    "    return [(station['latitude'], station['longitude']) for station in cursor]\n",
    "\n",
    "# Extracting latitudes and longitudes\n",
    "start_station_coordinates = extract_lat_long(top_start_stations)\n",
    "end_station_coordinates = extract_lat_long(top_end_stations)\n",
    "\n",
    "# Now there are two lists of tuples containing the latitudes and longitudes\n",
    "# of the top 10 start and end stations, respectively:\n",
    "print(\"Start Stations Coordinates:\", start_station_coordinates)\n",
    "print(\"End Stations Coordinates:\", end_station_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 71269, 'latitude': 41.880958, 'longitude': -87.616743}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 39251, 'latitude': 41.867888, 'longitude': -87.623041}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 37698, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 37208, 'latitude': 41.869265218438194, 'longitude': -87.67373085021973}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34508, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Millennium Park', 'count': 32849, 'latitude': 41.8810317, 'longitude': -87.62408432}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32560, 'latitude': 41.920771, 'longitude': -87.663712}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 31614, 'latitude': 41.893992, 'longitude': -87.629318}\n",
      "{'_id': 'Theater on the Lake', 'count': 31283, 'latitude': 41.926277, 'longitude': -87.630834}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28978, 'latitude': 41.893992, 'longitude': -87.629318}\n"
     ]
    }
   ],
   "source": [
    "# Pull in the data from Top10StartStations from original database\n",
    "collection_name = 'Top10StartStationsCopy'\n",
    "collection = db2[collection_name]\n",
    "# The find() method without any parameters will return all documents in the collection\n",
    "documents = collection.find()\n",
    "\n",
    "# Print each document\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.command_cursor.CommandCursor at 0x1d115b1b910>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the Top 10 Start and End Station collections to edit them without affecting the originals, and add the zip codes to the collections\n",
    "# Perform the duplication for Top10StartStations\n",
    "db['Top10StartStations'].aggregate([\n",
    "    {\"$match\": {}},  # This matches all documents and effectively copies them\n",
    "    {\"$out\": \"Top10StartStationsCopy\"}  # The name of the new collection for start stations\n",
    "])\n",
    "\n",
    "# Perform the duplication for Top10EndStations\n",
    "db['Top10EndStations'].aggregate([\n",
    "    {\"$match\": {}},  # This matches all documents and effectively copies them\n",
    "    {\"$out\": \"Top10EndStationsCopy\"}  # The name of the new collection for end stations\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see that end stations was copied correctly\n",
    "collection_name = 'Top10EndStationsCopy'\n",
    "collection = db2[collection_name]\n",
    "# The find() method without any parameters will return all documents in the collection\n",
    "documents = collection.find()\n",
    "\n",
    "# Print each document\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates: (41.880958, -87.616743) => ZIP Code: 60601\n",
      "Coordinates: (41.892278, -87.612043) => ZIP Code: 60611\n",
      "Coordinates: (41.867888, -87.623041) => ZIP Code: 60605\n",
      "Coordinates: (41.911722, -87.626804) => ZIP Code: 60614\n",
      "Coordinates: (41.897448, -87.628722) => ZIP Code: 60654\n",
      "Coordinates: (41.880958, -87.616743) => ZIP Code: 60601\n",
      "Coordinates: (41.869265218438194, -87.67373085021973) => ZIP Code: 60612\n",
      "Coordinates: (41.90096039, -87.62377664) => ZIP Code: 60611\n",
      "Coordinates: (41.897448, -87.628722) => ZIP Code: 60654\n",
      "Coordinates: (41.912133, -87.634656) => ZIP Code: 60614\n",
      "Coordinates: (41.8810317, -87.62408432) => ZIP Code: 60601\n",
      "Coordinates: (41.8810317, -87.62408432) => ZIP Code: 60601\n",
      "Coordinates: (41.920771, -87.663712) => ZIP Code: 60614\n",
      "Coordinates: (41.902973, -87.63128) => ZIP Code: 60610\n",
      "Coordinates: (41.893992, -87.629318) => ZIP Code: 60654\n",
      "Coordinates: (41.926277, -87.630834) => ZIP Code: 60657\n",
      "Coordinates: (41.926277, -87.630834) => ZIP Code: 60657\n",
      "Coordinates: (41.88917683258, -87.6385057718) => ZIP Code: 60654\n",
      "Coordinates: (41.893992, -87.629318) => ZIP Code: 60654\n",
      "Coordinates: (41.903222, -87.634324) => ZIP Code: 60610\n"
     ]
    }
   ],
   "source": [
    "# Find the zip codes corresponding to each latitude and longitude using LocationIQ API\n",
    "\n",
    "# Endpoint URL for reverse geocoding\n",
    "URL = 'https://us1.locationiq.com/v1/reverse.php'\n",
    "\n",
    "# Change variable name for start and end station coordinates\n",
    "coordinates_list1 = start_station_coordinates\n",
    "coordinates_list2 = end_station_coordinates\n",
    "\n",
    "# Function to retrieve postal codes from two lists of coordinates \n",
    "def get_zip_codes_locationiq(start_station_coordinates, end_station_coordinates, api_key):\n",
    "    zip_codes = []\n",
    "    for (lat1, lon1), (lat2, lon2) in zip(start_station_coordinates, end_station_coordinates):\n",
    "        for lat, lon in [(lat1, lon1), (lat2, lon2)]:\n",
    "            params = {\n",
    "                'key': api_key,\n",
    "                'lat': lat,\n",
    "                'lon': lon,\n",
    "                'format': 'json'\n",
    "            }\n",
    "            \n",
    "            # Make the request to LocationIQ\n",
    "            response = requests.get(URL, params=params)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                # Check if postcode is available in the response\n",
    "                zip_code = data.get('address', {}).get('postcode', None)\n",
    "                zip_codes.append((lat, lon, zip_code))\n",
    "            else:\n",
    "                print(f\"Error for {lat}, {lon}: {response.text}\")\n",
    "                zip_codes.append((lat, lon, None))\n",
    "            \n",
    "            # Respect the free tier limit of 1 request per second\n",
    "            time.sleep(1)\n",
    "    \n",
    "    return zip_codes\n",
    "\n",
    "# Retrieve ZIP codes for the provided coordinates\n",
    "zip_codes_list = get_zip_codes_locationiq(coordinates_list1, coordinates_list2, api_key_zip)\n",
    "\n",
    "# Output the results\n",
    "for lat, lon, zip_code in zip_codes_list:\n",
    "    print(f\"Coordinates: ({lat}, {lon}) => ZIP Code: {zip_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 71269, 'latitude': 41.880958, 'longitude': -87.616743}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 39251, 'latitude': 41.867888, 'longitude': -87.623041}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 37698, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 37208, 'latitude': 41.869265218438194, 'longitude': -87.67373085021973}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34508, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Millennium Park', 'count': 32849, 'latitude': 41.8810317, 'longitude': -87.62408432}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32560, 'latitude': 41.920771, 'longitude': -87.663712}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 31614, 'latitude': 41.893992, 'longitude': -87.629318}\n",
      "{'_id': 'Theater on the Lake', 'count': 31283, 'latitude': 41.926277, 'longitude': -87.630834}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28978, 'latitude': 41.893992, 'longitude': -87.629318}\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure the collections were copied correctly\n",
    "collection_name = 'Top10StartStationsCopy'\n",
    "collection = db[collection_name]\n",
    "# The find() method without any parameters will return all documents in the collection\n",
    "documents = collection.find()\n",
    "\n",
    "# Print each document\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated document with ZIP code 60601 for coordinates (41.880958, -87.616743)\n",
      "Updated document with ZIP code 60611 for coordinates (41.892278, -87.612043)\n",
      "Updated document with ZIP code 60605 for coordinates (41.867888, -87.623041)\n",
      "Updated document with ZIP code 60614 for coordinates (41.911722, -87.626804)\n",
      "Updated document with ZIP code 60654 for coordinates (41.897448, -87.628722)\n",
      "Updated document with ZIP code 60601 for coordinates (41.880958, -87.616743)\n",
      "Updated document with ZIP code 60612 for coordinates (41.869265218438194, -87.67373085021973)\n",
      "Updated document with ZIP code 60611 for coordinates (41.90096039, -87.62377664)\n",
      "Updated document with ZIP code 60654 for coordinates (41.897448, -87.628722)\n",
      "Updated document with ZIP code 60614 for coordinates (41.912133, -87.634656)\n",
      "Updated document with ZIP code 60601 for coordinates (41.8810317, -87.62408432)\n",
      "Updated document with ZIP code 60601 for coordinates (41.8810317, -87.62408432)\n",
      "Updated document with ZIP code 60614 for coordinates (41.920771, -87.663712)\n",
      "Updated document with ZIP code 60610 for coordinates (41.902973, -87.63128)\n",
      "Updated document with ZIP code 60654 for coordinates (41.893992, -87.629318)\n",
      "Updated document with ZIP code 60657 for coordinates (41.926277, -87.630834)\n",
      "Updated document with ZIP code 60657 for coordinates (41.926277, -87.630834)\n",
      "Updated document with ZIP code 60654 for coordinates (41.88917683258, -87.6385057718)\n",
      "Updated document with ZIP code 60654 for coordinates (41.893992, -87.629318)\n",
      "Updated document with ZIP code 60610 for coordinates (41.903222, -87.634324)\n",
      "Updated document with ZIP code 60601 for coordinates (41.880958, -87.616743)\n",
      "Updated document with ZIP code 60611 for coordinates (41.892278, -87.612043)\n",
      "Updated document with ZIP code 60605 for coordinates (41.867888, -87.623041)\n",
      "Updated document with ZIP code 60614 for coordinates (41.911722, -87.626804)\n",
      "Updated document with ZIP code 60654 for coordinates (41.897448, -87.628722)\n",
      "Updated document with ZIP code 60601 for coordinates (41.880958, -87.616743)\n",
      "Updated document with ZIP code 60612 for coordinates (41.869265218438194, -87.67373085021973)\n",
      "Updated document with ZIP code 60611 for coordinates (41.90096039, -87.62377664)\n",
      "Updated document with ZIP code 60654 for coordinates (41.897448, -87.628722)\n",
      "Updated document with ZIP code 60614 for coordinates (41.912133, -87.634656)\n",
      "Updated document with ZIP code 60601 for coordinates (41.8810317, -87.62408432)\n",
      "Updated document with ZIP code 60601 for coordinates (41.8810317, -87.62408432)\n",
      "Updated document with ZIP code 60614 for coordinates (41.920771, -87.663712)\n",
      "Updated document with ZIP code 60610 for coordinates (41.902973, -87.63128)\n",
      "Updated document with ZIP code 60654 for coordinates (41.893992, -87.629318)\n",
      "Updated document with ZIP code 60657 for coordinates (41.926277, -87.630834)\n",
      "Updated document with ZIP code 60657 for coordinates (41.926277, -87.630834)\n",
      "Updated document with ZIP code 60654 for coordinates (41.88917683258, -87.6385057718)\n",
      "Updated document with ZIP code 60654 for coordinates (41.893992, -87.629318)\n",
      "Updated document with ZIP code 60610 for coordinates (41.903222, -87.634324)\n"
     ]
    }
   ],
   "source": [
    "# Function to update (and create if doesn't exist) collections with ZIP codes based on matching coordinates\n",
    "def update_station_zip_codes(collection_name, zip_codes_list):\n",
    "    collection = db[collection_name]\n",
    "    for lat, lon, zip_code in zip_codes_list:\n",
    "        # Ensure the ZIP code is not None\n",
    "        if zip_code:\n",
    "            # Build the query to find the matching document by its coordinates\n",
    "            query = {\n",
    "                'latitude': lat,\n",
    "                'longitude': lon\n",
    "            }\n",
    "            # Build the update statement to set the ZIP code\n",
    "            update = {\n",
    "                '$setOnInsert': query,  # Set the coordinates on insert\n",
    "                '$set': {'zip_code': zip_code}  # Set the ZIP code on insert or update\n",
    "            }\n",
    "            # Update the document in the collection, upserting if it does not exist\n",
    "            result = collection.update_one(query, update, upsert=False)\n",
    "            if result.upserted_id is not None:\n",
    "                print(f\"Inserted document with ZIP code {zip_code} for coordinates ({lat}, {lon})\")\n",
    "            else:\n",
    "                print(f\"Updated document with ZIP code {zip_code} for coordinates ({lat}, {lon})\")\n",
    "\n",
    "# Now call the function with the new collection names\n",
    "update_station_zip_codes('Top10StartStationsCopy', zip_codes_list)\n",
    "update_station_zip_codes('Top10EndStationsCopy', zip_codes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 72540, 'latitude': 41.892278, 'longitude': -87.612043, 'zip_code': '60611'}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 40563, 'latitude': 41.911722, 'longitude': -87.626804, 'zip_code': '60614'}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 38500, 'latitude': 41.880958, 'longitude': -87.616743, 'zip_code': '60601'}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 38279, 'latitude': 41.90096039, 'longitude': -87.62377664, 'zip_code': '60611'}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34688, 'latitude': 41.912133, 'longitude': -87.634656, 'zip_code': '60614'}\n",
      "{'_id': 'Millennium Park', 'count': 33705, 'latitude': 41.8810317, 'longitude': -87.62408432, 'zip_code': '60601'}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32227, 'latitude': 41.902973, 'longitude': -87.63128, 'zip_code': '60610'}\n",
      "{'_id': 'Theater on the Lake', 'count': 31672, 'latitude': 41.926277, 'longitude': -87.630834, 'zip_code': '60657'}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 30450, 'latitude': 41.88917683258, 'longitude': -87.6385057718, 'zip_code': '60654'}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28346, 'latitude': 41.903222, 'longitude': -87.634324, 'zip_code': '60610'}\n"
     ]
    }
   ],
   "source": [
    "# Check to see that end stations was copied correctly\n",
    "collection_name = 'Top10EndStationsCopy'\n",
    "collection = db[collection_name]\n",
    "# The find() method without any parameters will return all documents in the collection\n",
    "documents = collection.find()\n",
    "\n",
    "# Print each document\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 71269, 'latitude': 41.880958, 'longitude': -87.616743, 'zip_code': '60601'}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 39251, 'latitude': 41.867888, 'longitude': -87.623041, 'zip_code': '60605'}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 37698, 'latitude': 41.897448, 'longitude': -87.628722, 'zip_code': '60654'}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 37208, 'latitude': 41.869265218438194, 'longitude': -87.67373085021973, 'zip_code': '60612'}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34508, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Millennium Park', 'count': 32849, 'latitude': 41.8810317, 'longitude': -87.62408432, 'zip_code': '60601'}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32560, 'latitude': 41.920771, 'longitude': -87.663712, 'zip_code': '60614'}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 31614, 'latitude': 41.893992, 'longitude': -87.629318, 'zip_code': '60654'}\n",
      "{'_id': 'Theater on the Lake', 'count': 31283, 'latitude': 41.926277, 'longitude': -87.630834, 'zip_code': '60657'}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28978, 'latitude': 41.893992, 'longitude': -87.629318}\n"
     ]
    }
   ],
   "source": [
    "# Check to see that end stations was copied correctly\n",
    "collection_name = 'Top10StartStationsCopy'\n",
    "collection = db[collection_name]\n",
    "# The find() method without any parameters will return all documents in the collection\n",
    "documents = collection.find()\n",
    "\n",
    "# Print each document\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID Streeter Dr & Grand Ave has ZIP code: 60601\n",
      "Document ID DuSable Lake Shore Dr & Monroe St has ZIP code: 60605\n",
      "Document ID DuSable Lake Shore Dr & North Blvd has ZIP code: 60654\n",
      "Document ID Michigan Ave & Oak St has ZIP code: 60612\n",
      "Document ID Wells St & Concord Ln does not have a ZIP code or it's set to None.\n",
      "Document ID Millennium Park has ZIP code: 60601\n",
      "Document ID Clark St & Elm St has ZIP code: 60614\n",
      "Document ID Kingsbury St & Kinzie St has ZIP code: 60654\n",
      "Document ID Theater on the Lake has ZIP code: 60657\n",
      "Document ID Wells St & Elm St does not have a ZIP code or it's set to None.\n",
      "Document ID Streeter Dr & Grand Ave has ZIP code: 60611\n",
      "Document ID DuSable Lake Shore Dr & North Blvd has ZIP code: 60614\n",
      "Document ID DuSable Lake Shore Dr & Monroe St has ZIP code: 60601\n",
      "Document ID Michigan Ave & Oak St has ZIP code: 60611\n",
      "Document ID Wells St & Concord Ln has ZIP code: 60614\n",
      "Document ID Millennium Park has ZIP code: 60601\n",
      "Document ID Clark St & Elm St has ZIP code: 60610\n",
      "Document ID Theater on the Lake has ZIP code: 60657\n",
      "Document ID Kingsbury St & Kinzie St has ZIP code: 60654\n",
      "Document ID Wells St & Elm St has ZIP code: 60610\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure the zip codes were put into the collections correctly\n",
    "# Collections to check\n",
    "collections_to_check = ['Top10StartStationsCopy', 'Top10EndStationsCopy']\n",
    "\n",
    "for collection_name in collections_to_check:\n",
    "    collection = db[collection_name]\n",
    "    # Fetch all documents in the collection\n",
    "    documents = collection.find({})\n",
    "\n",
    "    # Iterate through the documents and check the 'zip_code' field\n",
    "    for doc in documents:\n",
    "        if 'zip_code' in doc and doc['zip_code'] is not None:\n",
    "            print(f\"Document ID {doc['_id']} has ZIP code: {doc['zip_code']}\")\n",
    "        else:\n",
    "            print(f\"Document ID {doc['_id']} does not have a ZIP code or it's set to None.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The population for ZIP code 60601 is 15083\n",
      "The population for ZIP code 60611 is 33224\n",
      "The population for ZIP code 60605 is 29060\n",
      "The population for ZIP code 60614 is 71954\n",
      "The population for ZIP code 60654 is 20022\n",
      "The population for ZIP code 60612 is 33735\n",
      "The population for ZIP code 60610 is 40548\n",
      "The population for ZIP code 60657 is 70958\n"
     ]
    }
   ],
   "source": [
    "# Find the population for each zip code, using the American Community Survey (ACS) API.  We are using the ACS 5-year estimates as the 1 year estimates only cover areas with populations of 65,000 people or more\n",
    "\n",
    "# List of ZIP codes from zip_code_list tuple\n",
    "zip_codes = [tup[2] for tup in zip_codes_list if len(tup)>2]\n",
    "\n",
    "# Your API key for the U.S. Census Bureau\n",
    "api_key = api_key_census\n",
    "\n",
    "# The base URL for the ACS5 5-Year Estimates API\n",
    "base_url = 'https://api.census.gov/data/2019/acs/acs5'\n",
    "\n",
    "# The variable code for total population\n",
    "population_variable = 'B01003_001E'\n",
    "\n",
    "# Dictionary to store the population data\n",
    "population_data = {}\n",
    "\n",
    "# Function to retrieve population by ZIP code\n",
    "def get_population_by_zip(zip_code):\n",
    "    parameters = {\n",
    "        'get': population_variable,\n",
    "        'for': f'zip code tabulation area:{zip_code}',\n",
    "        'in': 'state:17',  # Adding the state code for Illinois\n",
    "        'key': api_key\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(base_url, params=parameters)\n",
    "        response.raise_for_status()  # This will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "        data = response.json()\n",
    "        # Assuming the first element is headers, the second is data\n",
    "        return int(data[1][0])\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print(f\"HTTP Error for ZIP code {zip_code}: {errh}\")\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(f\"Error Connecting for ZIP code {zip_code}: {errc}\")\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print(f\"Timeout Error for ZIP code {zip_code}: {errt}\")\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(f\"Error for ZIP code {zip_code}: {err}\")\n",
    "    return None\n",
    "\n",
    "# Retrieve the population for each ZIP code and store in the dictionary\n",
    "for zip_code in zip_codes:\n",
    "    population_data[zip_code] = get_population_by_zip(zip_code)\n",
    "\n",
    "# Print out the population data\n",
    "for zip_code, population in population_data.items():\n",
    "    if population is not None:\n",
    "        print(f\"The population for ZIP code {zip_code} is {population}\")\n",
    "    else:\n",
    "        print(f\"Population data not available for ZIP code {zip_code}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 1 documents in collection 'Top10StartStationsCopy' with ZIP code 60605 to population 29060\n",
      "Updated 2 documents in collection 'Top10StartStationsCopy' with ZIP code 60601 to population 15083\n",
      "Updated 1 documents in collection 'Top10StartStationsCopy' with ZIP code 60612 to population 33735\n",
      "Updated 0 documents in collection 'Top10StartStationsCopy' with ZIP code 60611 to population 33224\n",
      "Updated 2 documents in collection 'Top10StartStationsCopy' with ZIP code 60654 to population 20022\n",
      "Updated 1 documents in collection 'Top10StartStationsCopy' with ZIP code 60657 to population 70958\n",
      "Updated 1 documents in collection 'Top10StartStationsCopy' with ZIP code 60614 to population 71954\n",
      "Updated 0 documents in collection 'Top10StartStationsCopy' with ZIP code 60610 to population 40548\n",
      "Updated 0 documents in collection 'Top10EndStationsCopy' with ZIP code 60605 to population 29060\n",
      "Updated 2 documents in collection 'Top10EndStationsCopy' with ZIP code 60601 to population 15083\n",
      "Updated 0 documents in collection 'Top10EndStationsCopy' with ZIP code 60612 to population 33735\n",
      "Updated 2 documents in collection 'Top10EndStationsCopy' with ZIP code 60611 to population 33224\n",
      "Updated 1 documents in collection 'Top10EndStationsCopy' with ZIP code 60654 to population 20022\n",
      "Updated 1 documents in collection 'Top10EndStationsCopy' with ZIP code 60657 to population 70958\n",
      "Updated 2 documents in collection 'Top10EndStationsCopy' with ZIP code 60614 to population 71954\n",
      "Updated 2 documents in collection 'Top10EndStationsCopy' with ZIP code 60610 to population 40548\n"
     ]
    }
   ],
   "source": [
    "# Add population data back with Top 10 Start Stations and Top 10 End Stations collections\n",
    "\n",
    "# Connect to collections\n",
    "start_stations_collection = db.Top10StartStationsCopy\n",
    "end_stations_collection = db.Top10EndStationsCopy\n",
    "\n",
    "# Retrieve the population data for each ZIP code from the census API\n",
    "def get_population_data(api_key_census, zip_codes):\n",
    "    population_data = {}\n",
    "    for zip_code in zip_codes:\n",
    "        # Construct the API request URL\n",
    "        response = requests.get(\n",
    "            f\"https://api.census.gov/data/2019/acs/acs5\",\n",
    "            params={\n",
    "                'get': 'B01003_001E',\n",
    "                'for': f'zip code tabulation area:{zip_code}',\n",
    "                'in': 'state:17',  # Illinois state code\n",
    "                'key': api_key_census\n",
    "            }\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # Extract the population count and update the population_data dictionary\n",
    "            population_data[zip_code] = int(data[1][0])\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data for ZIP code {zip_code}: {response.text}\")\n",
    "    \n",
    "    return population_data\n",
    "\n",
    "# Function to update the station documents with population data\n",
    "def update_stations_with_population(collection, population_data):\n",
    "    for zip_code, population in population_data.items():\n",
    "        # Update documents in the collection with the matching ZIP code\n",
    "        result = collection.update_many(\n",
    "            {'zip_code': zip_code},\n",
    "            {'$set': {'population': population}}\n",
    "        )\n",
    "        print(f\"Updated {result.modified_count} documents in collection '{collection.name}' with ZIP code {zip_code} to population {population}\")\n",
    "\n",
    "# Retrieve a list of unique ZIP codes from both collections, safely checking for the 'zip_code' field\n",
    "relevant_zip_codes = []\n",
    "for collection in [start_stations_collection, end_stations_collection]:\n",
    "    for doc in collection.find():\n",
    "        zip_code = doc.get('zip_code')\n",
    "        if zip_code:\n",
    "            relevant_zip_codes.append(zip_code)\n",
    "relevant_zip_codes = list(set(relevant_zip_codes))  # Remove duplicates\n",
    "\n",
    "# Retrieve population data for the relevant ZIP codes\n",
    "population_data = get_population_data(api_key_census, relevant_zip_codes)\n",
    "\n",
    "# Update the collections with the population data\n",
    "update_stations_with_population(start_stations_collection, population_data)\n",
    "update_stations_with_population(end_stations_collection, population_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 71269, 'latitude': 41.880958, 'longitude': -87.616743, 'zip_code': '60601', 'population': 15083}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 39251, 'latitude': 41.867888, 'longitude': -87.623041, 'zip_code': '60605', 'population': 29060}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 37698, 'latitude': 41.897448, 'longitude': -87.628722, 'zip_code': '60654', 'population': 20022}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 37208, 'latitude': 41.869265218438194, 'longitude': -87.67373085021973, 'zip_code': '60612', 'population': 33735}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34508, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Millennium Park', 'count': 32849, 'latitude': 41.8810317, 'longitude': -87.62408432, 'zip_code': '60601', 'population': 15083}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32560, 'latitude': 41.920771, 'longitude': -87.663712, 'zip_code': '60614', 'population': 71954}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 31614, 'latitude': 41.893992, 'longitude': -87.629318, 'zip_code': '60654', 'population': 20022}\n",
      "{'_id': 'Theater on the Lake', 'count': 31283, 'latitude': 41.926277, 'longitude': -87.630834, 'zip_code': '60657', 'population': 70958}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28978, 'latitude': 41.893992, 'longitude': -87.629318}\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure the collections were copied correctly\n",
    "collection_name = 'Top10StartStationsCopy'\n",
    "collection = db[collection_name]\n",
    "# The find() method without any parameters will return all documents in the collection\n",
    "documents = collection.find()\n",
    "\n",
    "# Print each document\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 72540, 'latitude': 41.892278, 'longitude': -87.612043, 'zip_code': '60611', 'population': 33224}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 40563, 'latitude': 41.911722, 'longitude': -87.626804, 'zip_code': '60614', 'population': 71954}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 38500, 'latitude': 41.880958, 'longitude': -87.616743, 'zip_code': '60601', 'population': 15083}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 38279, 'latitude': 41.90096039, 'longitude': -87.62377664, 'zip_code': '60611', 'population': 33224}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34688, 'latitude': 41.912133, 'longitude': -87.634656, 'zip_code': '60614', 'population': 71954}\n",
      "{'_id': 'Millennium Park', 'count': 33705, 'latitude': 41.8810317, 'longitude': -87.62408432, 'zip_code': '60601', 'population': 15083}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32227, 'latitude': 41.902973, 'longitude': -87.63128, 'zip_code': '60610', 'population': 40548}\n",
      "{'_id': 'Theater on the Lake', 'count': 31672, 'latitude': 41.926277, 'longitude': -87.630834, 'zip_code': '60657', 'population': 70958}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 30450, 'latitude': 41.88917683258, 'longitude': -87.6385057718, 'zip_code': '60654', 'population': 20022}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28346, 'latitude': 41.903222, 'longitude': -87.634324, 'zip_code': '60610', 'population': 40548}\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure the collections were copied correctly\n",
    "collection_name = 'Top10EndStationsCopy'\n",
    "collection = db[collection_name]\n",
    "# The find() method without any parameters will return all documents in the collection\n",
    "documents = collection.find()\n",
    "\n",
    "# Print each document\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'population'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\alici\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\alici\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alici\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'population'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alici\\Desktop\\Project-3-Divvying-in-the-Rain\\Census.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alici/Desktop/Project-3-Divvying-in-the-Rain/Census.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m df_pandas \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(mongo_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alici/Desktop/Project-3-Divvying-in-the-Rain/Census.ipynb#X32sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Calculate Pearson correlation coefficient and p-value\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/alici/Desktop/Project-3-Divvying-in-the-Rain/Census.ipynb#X32sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m correlation_coefficient, p_value \u001b[39m=\u001b[39m pearsonr(df_pandas[\u001b[39m'\u001b[39;49m\u001b[39mpopulation\u001b[39;49m\u001b[39m'\u001b[39;49m], df_pandas[\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alici/Desktop/Project-3-Divvying-in-the-Rain/Census.ipynb#X32sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Visualize the relationship with a scatter plot\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alici/Desktop/Project-3-Divvying-in-the-Rain/Census.ipynb#X32sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m plt\u001b[39m.\u001b[39mscatter(df_pandas[\u001b[39m'\u001b[39m\u001b[39mpopulation\u001b[39m\u001b[39m'\u001b[39m], df_pandas[\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\alici\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\alici\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'population'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db2 = client['chicago_bikes_copy']  # Replace 'your_database' with your actual database name\n",
    "collection = db2['Top10StartStationsCopy']  # Replace 'your_collection' with your actual collection name\n",
    "\n",
    "# Retrieve data from MongoDB collection\n",
    "cursor = collection.find({}, {'_id': 0, 'ZIP_code': 1, 'population': 1, 'count': 1})\n",
    "mongo_data = list(cursor)\n",
    "\n",
    "# Convert MongoDB data to DataFrame\n",
    "df_pandas = pd.DataFrame(mongo_data)\n",
    "\n",
    "# Calculate Pearson correlation coefficient and p-value\n",
    "correlation_coefficient, p_value = pearsonr(df_pandas['population'], df_pandas['count'])\n",
    "\n",
    "# Visualize the relationship with a scatter plot\n",
    "plt.scatter(df_pandas['population'], df_pandas['count'])\n",
    "plt.title(f'Population vs. Bike Usage\\nCorrelation: {correlation_coefficient:.2f}, p-value: {p_value:.4f}')\n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('Bike Usage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the MongoDB connection\n",
    "mongo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
