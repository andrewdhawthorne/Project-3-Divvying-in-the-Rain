{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient, UpdateOne\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from config import api_key_zip, api_key_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents in Top10StartStationsCopy:\n",
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 71269, 'latitude': 41.880958, 'longitude': -87.616743}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 39251, 'latitude': 41.867888, 'longitude': -87.623041}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 37698, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 37208, 'latitude': 41.869265218438194, 'longitude': -87.67373085021973}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34508, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Millennium Park', 'count': 32849, 'latitude': 41.8810317, 'longitude': -87.62408432}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32560, 'latitude': 41.920771, 'longitude': -87.663712}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 31614, 'latitude': 41.893992, 'longitude': -87.629318}\n",
      "{'_id': 'Theater on the Lake', 'count': 31283, 'latitude': 41.926277, 'longitude': -87.630834}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28978, 'latitude': 41.893992, 'longitude': -87.629318}\n",
      "\n",
      "Documents in Top10EndStationsCopy:\n",
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 72540, 'latitude': 41.892278, 'longitude': -87.612043}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 40563, 'latitude': 41.911722, 'longitude': -87.626804}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 38500, 'latitude': 41.880958, 'longitude': -87.616743}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 38279, 'latitude': 41.90096039, 'longitude': -87.62377664}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34688, 'latitude': 41.912133, 'longitude': -87.634656}\n",
      "{'_id': 'Millennium Park', 'count': 33705, 'latitude': 41.8810317, 'longitude': -87.62408432}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32227, 'latitude': 41.902973, 'longitude': -87.63128}\n",
      "{'_id': 'Theater on the Lake', 'count': 31672, 'latitude': 41.926277, 'longitude': -87.630834}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 30450, 'latitude': 41.88917683258, 'longitude': -87.6385057718}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28346, 'latitude': 41.903222, 'longitude': -87.634324}\n"
     ]
    }
   ],
   "source": [
    "# Create a new database to hold copies of collections as to not interfere with data in the original collections\n",
    "# MongoDB connection URI\n",
    "mongo_uri = \"mongodb://localhost:27017/\"\n",
    "mongo = MongoClient(mongo_uri)\n",
    "\n",
    "# Connect to the original database\n",
    "db = mongo.chicago_bikes\n",
    "\n",
    "# Connect to the collections in the original database\n",
    "start_stations_original = db['Top10StartStations']\n",
    "end_stations_original = db['Top10EndStations']\n",
    "\n",
    "# Connect to the new database\n",
    "db2 = mongo[\"chicago_bikes_copy\"]\n",
    "\n",
    "# Specify the names of the new collections\n",
    "new_start_collection_name = 'Top10StartStationsCopy'\n",
    "new_end_collection_name = 'Top10EndStationsCopy'\n",
    "\n",
    "# Drop existing collections with the same names in the new database (if needed)\n",
    "db2[new_start_collection_name].drop()\n",
    "db2[new_end_collection_name].drop()\n",
    "\n",
    "# Create new collections in the new database\n",
    "db2[new_start_collection_name].insert_many(start_stations_original.find())\n",
    "db2[new_end_collection_name].insert_many(end_stations_original.find())\n",
    "\n",
    "# Print each document in the new start stations collection to verify the data transfer\n",
    "print(f\"Documents in {new_start_collection_name}:\")\n",
    "for doc in db2[new_start_collection_name].find():\n",
    "    print(doc)\n",
    "\n",
    "# Print each document in the new end stations collection to verify the data transfer\n",
    "print(f\"\\nDocuments in {new_end_collection_name}:\")\n",
    "for doc in db2[new_end_collection_name].find():\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Stations Coordinates: [(41.880958, -87.616743), (41.867888, -87.623041), (41.897448, -87.628722), (41.869265218438194, -87.67373085021973), (41.897448, -87.628722), (41.8810317, -87.62408432), (41.920771, -87.663712), (41.893992, -87.629318), (41.926277, -87.630834), (41.893992, -87.629318)]\n",
      "End Stations Coordinates: [(41.892278, -87.612043), (41.911722, -87.626804), (41.880958, -87.616743), (41.90096039, -87.62377664), (41.912133, -87.634656), (41.8810317, -87.62408432), (41.902973, -87.63128), (41.926277, -87.630834), (41.88917683258, -87.6385057718), (41.903222, -87.634324)]\n"
     ]
    }
   ],
   "source": [
    "# Get the latitude and longitude from the top 10 stations and top 10 end stations\n",
    "\n",
    "# Connect to collections\n",
    "new_start_stations_collection = db2.Top10StartStationsCopy\n",
    "new_end_stations_collection = db2.Top10EndStationsCopy\n",
    "\n",
    "# Fetch the top 10 start and end stations\n",
    "top_start_stations = new_start_stations_collection.find({}, {'_id': 0, 'latitude': 1, 'longitude': 1})\n",
    "top_end_stations = new_end_stations_collection.find({}, {'_id': 0, 'latitude': 1, 'longitude': 1})\n",
    "\n",
    "# Function to iterate over the cursor and extract lat and long data\n",
    "def extract_lat_long(cursor):\n",
    "    return [(station['latitude'], station['longitude']) for station in cursor]\n",
    "\n",
    "# Extracting latitudes and longitudes\n",
    "start_station_coordinates = extract_lat_long(top_start_stations)\n",
    "end_station_coordinates = extract_lat_long(top_end_stations)\n",
    "\n",
    "# Now there are two lists of tuples containing the latitudes and longitudes\n",
    "# of the top 10 start and end stations, respectively:\n",
    "print(\"Start Stations Coordinates:\", start_station_coordinates)\n",
    "print(\"End Stations Coordinates:\", end_station_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new database to hold the new collections\n",
    "# Already connected to the database\n",
    "db2 = mongo[\"chicago_bikes_copy\"]\n",
    "\n",
    "# Add the collections to the database\n",
    "Top10StartStationsCopy = db2[\"Top10StartStationsCopy\"]\n",
    "Top10EndStationsCopy = db2[\"Top10EndStationsCopy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 71269, 'latitude': 41.880958, 'longitude': -87.616743}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 39251, 'latitude': 41.867888, 'longitude': -87.623041}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 37698, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 37208, 'latitude': 41.869265218438194, 'longitude': -87.67373085021973}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34508, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Millennium Park', 'count': 32849, 'latitude': 41.8810317, 'longitude': -87.62408432}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32560, 'latitude': 41.920771, 'longitude': -87.663712}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 31614, 'latitude': 41.893992, 'longitude': -87.629318}\n",
      "{'_id': 'Theater on the Lake', 'count': 31283, 'latitude': 41.926277, 'longitude': -87.630834}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28978, 'latitude': 41.893992, 'longitude': -87.629318}\n"
     ]
    }
   ],
   "source": [
    "# Pull in the data from Top10StartStations from original database\n",
    "collection_name = 'Top10StartStationsCopy'\n",
    "collection = db2[collection_name]\n",
    "# The find() method without any parameters will return all documents in the collection\n",
    "documents = collection.find()\n",
    "\n",
    "# Print each document\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.command_cursor.CommandCursor at 0x214c0b47b20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the Top 10 Start and End Station collections to edit them without affecting the originals, and add the zip codes to the collections\n",
    "# Perform the duplication for Top10StartStations\n",
    "db['Top10StartStations'].aggregate([\n",
    "    {\"$match\": {}},  # This matches all documents and effectively copies them\n",
    "    {\"$out\": \"Top10StartStationsCopy\"}  # The name of the new collection for start stations\n",
    "])\n",
    "\n",
    "# Perform the duplication for Top10EndStations\n",
    "db['Top10EndStations'].aggregate([\n",
    "    {\"$match\": {}},  # This matches all documents and effectively copies them\n",
    "    {\"$out\": \"Top10EndStationsCopy\"}  # The name of the new collection for end stations\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 72540, 'latitude': 41.892278, 'longitude': -87.612043}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 40563, 'latitude': 41.911722, 'longitude': -87.626804}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 38500, 'latitude': 41.880958, 'longitude': -87.616743}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 38279, 'latitude': 41.90096039, 'longitude': -87.62377664}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34688, 'latitude': 41.912133, 'longitude': -87.634656}\n",
      "{'_id': 'Millennium Park', 'count': 33705, 'latitude': 41.8810317, 'longitude': -87.62408432}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32227, 'latitude': 41.902973, 'longitude': -87.63128}\n",
      "{'_id': 'Theater on the Lake', 'count': 31672, 'latitude': 41.926277, 'longitude': -87.630834}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 30450, 'latitude': 41.88917683258, 'longitude': -87.6385057718}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28346, 'latitude': 41.903222, 'longitude': -87.634324}\n"
     ]
    }
   ],
   "source": [
    "# Check to see that end stations was copied correctly\n",
    "collection_name = 'Top10EndStationsCopy'\n",
    "collection = db2[collection_name]\n",
    "# The find() method without any parameters will return all documents in the collection\n",
    "documents = collection.find()\n",
    "\n",
    "# Print each document\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated document with ZIP code 60601 for coordinates (41.880958, -87.616743)\n",
      "Updated document with ZIP code 60605 for coordinates (41.867888, -87.623041)\n",
      "Updated document with ZIP code 60654 for coordinates (41.897448, -87.628722)\n",
      "Updated document with ZIP code 60612 for coordinates (41.869265218438194, -87.67373085021973)\n",
      "No document updated for coordinates (41.897448, -87.628722)\n",
      "Updated document with ZIP code 60601 for coordinates (41.8810317, -87.62408432)\n",
      "Updated document with ZIP code 60614 for coordinates (41.920771, -87.663712)\n",
      "Updated document with ZIP code 60654 for coordinates (41.893992, -87.629318)\n",
      "Updated document with ZIP code 60657 for coordinates (41.926277, -87.630834)\n",
      "No document updated for coordinates (41.893992, -87.629318)\n",
      "Updated document with ZIP code 60611 for coordinates (41.892278, -87.612043)\n",
      "Updated document with ZIP code 60614 for coordinates (41.911722, -87.626804)\n",
      "Updated document with ZIP code 60601 for coordinates (41.880958, -87.616743)\n",
      "Updated document with ZIP code 60611 for coordinates (41.90096039, -87.62377664)\n",
      "Updated document with ZIP code 60614 for coordinates (41.912133, -87.634656)\n",
      "Updated document with ZIP code 60601 for coordinates (41.8810317, -87.62408432)\n",
      "Updated document with ZIP code 60610 for coordinates (41.902973, -87.63128)\n",
      "Updated document with ZIP code 60657 for coordinates (41.926277, -87.630834)\n",
      "Updated document with ZIP code 60654 for coordinates (41.88917683258, -87.6385057718)\n",
      "Updated document with ZIP code 60610 for coordinates (41.903222, -87.634324)\n"
     ]
    }
   ],
   "source": [
    "# Function to update a collection with ZIP codes based on matching coordinates\n",
    "def update_collection_with_zip_codes(collection, coordinates_list, api_key):\n",
    "    for lat, lon in coordinates_list:\n",
    "        params = {\n",
    "            'key': api_key,\n",
    "            'lat': lat,\n",
    "            'lon': lon,\n",
    "            'format': 'json'\n",
    "        }\n",
    "\n",
    "        # Make the request to LocationIQ\n",
    "        response = requests.get('https://us1.locationiq.com/v1/reverse.php', params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # Check if postcode is available in the response\n",
    "            zip_code = data.get('address', {}).get('postcode', None)\n",
    "\n",
    "            # Update the document in the collection with the ZIP code\n",
    "            result = collection.update_one(\n",
    "                {'latitude': lat, 'longitude': lon},\n",
    "                {'$set': {'zip_code': zip_code}},\n",
    "                upsert=False\n",
    "            )\n",
    "\n",
    "            if result.modified_count > 0:\n",
    "                print(f\"Updated document with ZIP code {zip_code} for coordinates ({lat}, {lon})\")\n",
    "            else:\n",
    "                print(f\"No document updated for coordinates ({lat}, {lon})\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Error for {lat}, {lon}: {response.text}\")\n",
    "\n",
    "        # Respect the free tier limit of 1 request per second\n",
    "        time.sleep(1)\n",
    "\n",
    "# Example usage:\n",
    "start_station_zip = update_collection_with_zip_codes(Top10StartStationsCopy, start_station_coordinates, api_key_zip)\n",
    "end_station_zip = update_collection_with_zip_codes(Top10EndStationsCopy, end_station_coordinates, api_key_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 71269, 'latitude': 41.880958, 'longitude': -87.616743, 'zip_code': '60601'}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 39251, 'latitude': 41.867888, 'longitude': -87.623041, 'zip_code': '60605'}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 37698, 'latitude': 41.897448, 'longitude': -87.628722, 'zip_code': '60654'}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 37208, 'latitude': 41.869265218438194, 'longitude': -87.67373085021973, 'zip_code': '60612'}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34508, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Millennium Park', 'count': 32849, 'latitude': 41.8810317, 'longitude': -87.62408432, 'zip_code': '60601'}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32560, 'latitude': 41.920771, 'longitude': -87.663712, 'zip_code': '60614'}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 31614, 'latitude': 41.893992, 'longitude': -87.629318, 'zip_code': '60654'}\n",
      "{'_id': 'Theater on the Lake', 'count': 31283, 'latitude': 41.926277, 'longitude': -87.630834, 'zip_code': '60657'}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28978, 'latitude': 41.893992, 'longitude': -87.629318}\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure the collections were copied correctly\n",
    "collection_name = 'Top10StartStationsCopy'\n",
    "collection = db2[collection_name]\n",
    "# The find() method without any parameters will return all documents in the collection\n",
    "documents = collection.find()\n",
    "\n",
    "# Print each document\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 72540, 'latitude': 41.892278, 'longitude': -87.612043, 'zip_code': '60611'}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 40563, 'latitude': 41.911722, 'longitude': -87.626804, 'zip_code': '60614'}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 38500, 'latitude': 41.880958, 'longitude': -87.616743, 'zip_code': '60601'}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 38279, 'latitude': 41.90096039, 'longitude': -87.62377664, 'zip_code': '60611'}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34688, 'latitude': 41.912133, 'longitude': -87.634656, 'zip_code': '60614'}\n",
      "{'_id': 'Millennium Park', 'count': 33705, 'latitude': 41.8810317, 'longitude': -87.62408432, 'zip_code': '60601'}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32227, 'latitude': 41.902973, 'longitude': -87.63128, 'zip_code': '60610'}\n",
      "{'_id': 'Theater on the Lake', 'count': 31672, 'latitude': 41.926277, 'longitude': -87.630834, 'zip_code': '60657'}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 30450, 'latitude': 41.88917683258, 'longitude': -87.6385057718, 'zip_code': '60654'}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28346, 'latitude': 41.903222, 'longitude': -87.634324, 'zip_code': '60610'}\n"
     ]
    }
   ],
   "source": [
    "# Check to see that end stations was copied correctly\n",
    "collection_name = 'Top10EndStationsCopy'\n",
    "collection = db2[collection_name]\n",
    "# The find() method without any parameters will return all documents in the collection\n",
    "documents = collection.find()\n",
    "\n",
    "# Print each document\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID Streeter Dr & Grand Ave does not have a ZIP code or it's set to None.\n",
      "Document ID DuSable Lake Shore Dr & Monroe St does not have a ZIP code or it's set to None.\n",
      "Document ID DuSable Lake Shore Dr & North Blvd does not have a ZIP code or it's set to None.\n",
      "Document ID Michigan Ave & Oak St does not have a ZIP code or it's set to None.\n",
      "Document ID Wells St & Concord Ln does not have a ZIP code or it's set to None.\n",
      "Document ID Millennium Park does not have a ZIP code or it's set to None.\n",
      "Document ID Clark St & Elm St does not have a ZIP code or it's set to None.\n",
      "Document ID Kingsbury St & Kinzie St does not have a ZIP code or it's set to None.\n",
      "Document ID Theater on the Lake does not have a ZIP code or it's set to None.\n",
      "Document ID Wells St & Elm St does not have a ZIP code or it's set to None.\n",
      "Document ID Streeter Dr & Grand Ave does not have a ZIP code or it's set to None.\n",
      "Document ID DuSable Lake Shore Dr & North Blvd does not have a ZIP code or it's set to None.\n",
      "Document ID DuSable Lake Shore Dr & Monroe St does not have a ZIP code or it's set to None.\n",
      "Document ID Michigan Ave & Oak St does not have a ZIP code or it's set to None.\n",
      "Document ID Wells St & Concord Ln does not have a ZIP code or it's set to None.\n",
      "Document ID Millennium Park does not have a ZIP code or it's set to None.\n",
      "Document ID Clark St & Elm St does not have a ZIP code or it's set to None.\n",
      "Document ID Theater on the Lake does not have a ZIP code or it's set to None.\n",
      "Document ID Kingsbury St & Kinzie St does not have a ZIP code or it's set to None.\n",
      "Document ID Wells St & Elm St does not have a ZIP code or it's set to None.\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure the zip codes were put into the collections correctly\n",
    "# Collections to check\n",
    "collections_to_check = ['Top10StartStationsCopy', 'Top10EndStationsCopy']\n",
    "\n",
    "for collection_name in collections_to_check:\n",
    "    collection = db[collection_name]\n",
    "    # Fetch all documents in the collection\n",
    "    documents = collection.find({})\n",
    "\n",
    "    # Iterate through the documents and check the 'zip_code' field\n",
    "    for doc in documents:\n",
    "        if 'zip_code' in doc and doc['zip_code'] is not None:\n",
    "            print(f\"Document ID {doc['_id']} has ZIP code: {doc['zip_code']}\")\n",
    "        else:\n",
    "            print(f\"Document ID {doc['_id']} does not have a ZIP code or it's set to None.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The population for ZIP code 60601 is 15083\n",
      "The population for ZIP code 60654 is 20022\n",
      "The population for ZIP code 60614 is 71954\n",
      "The population for ZIP code 60610 is 40548\n",
      "The population for ZIP code 60612 is 33735\n",
      "The population for ZIP code 60605 is 29060\n",
      "The population for ZIP code 60611 is 33224\n",
      "The population for ZIP code 60657 is 70958\n"
     ]
    }
   ],
   "source": [
    "# Find the population for each zip code, using the American Community Survey (ACS) API.  We are using the ACS 5-year estimates as the 1 year estimates only cover areas with populations of 65,000 people or more\n",
    "\n",
    "# Assign the collections\n",
    "start_collection = db2['Top10StartStationsCopy']\n",
    "end_collection = db2['Top10EndStationsCopy']\n",
    "\n",
    "# Function to extract ZIP codes from a collection\n",
    "def extract_zip_codes_from_collection(collection):\n",
    "    zip_codes = set()\n",
    "    for document in collection.find({}, {'_id': 0, 'zip_code': 1}):\n",
    "        zip_code = document.get('zip_code')\n",
    "        if zip_code:\n",
    "            zip_codes.add(zip_code)\n",
    "    return list(zip_codes)\n",
    "\n",
    "# Extract ZIP codes from the start and end collections\n",
    "start_zip_codes = extract_zip_codes_from_collection(start_collection)\n",
    "end_zip_codes = extract_zip_codes_from_collection(end_collection)\n",
    "\n",
    "# Combine all unique ZIP codes\n",
    "all_zip_codes = list(set(start_zip_codes + end_zip_codes))\n",
    "\n",
    "# Your API key for the U.S. Census Bureau\n",
    "api_key = api_key_census\n",
    "\n",
    "# The base URL for the ACS5 5-Year Estimates API\n",
    "base_url = 'https://api.census.gov/data/2019/acs/acs5'\n",
    "\n",
    "# The variable code for total population\n",
    "population_variable = 'B01003_001E'\n",
    "\n",
    "# Dictionary to store the population data\n",
    "population_data = {}\n",
    "\n",
    "# Function to retrieve population by ZIP code\n",
    "def get_population_by_zip(zip_code):\n",
    "    parameters = {\n",
    "        'get': population_variable,\n",
    "        'for': f'zip code tabulation area:{zip_code}',\n",
    "        'in': 'state:17',  # Adding the state code for Illinois\n",
    "        'key': api_key\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(base_url, params=parameters)\n",
    "        response.raise_for_status()  # This will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "        data = response.json()\n",
    "        # Assuming the first element is headers, the second is data\n",
    "        return int(data[1][0])\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print(f\"HTTP Error for ZIP code {zip_code}: {errh}\")\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(f\"Error Connecting for ZIP code {zip_code}: {errc}\")\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print(f\"Timeout Error for ZIP code {zip_code}: {errt}\")\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(f\"Error for ZIP code {zip_code}: {err}\")\n",
    "    return None\n",
    "\n",
    "# Retrieve the population for each ZIP code and store in the dictionary\n",
    "for zip_code in all_zip_codes:\n",
    "    population_data[zip_code] = get_population_by_zip(zip_code)\n",
    "\n",
    "# Print out the population data\n",
    "for zip_code, population in population_data.items():\n",
    "    if population is not None:\n",
    "        print(f\"The population for ZIP code {zip_code} is {population}\")\n",
    "    else:\n",
    "        print(f\"Population data not available for ZIP code {zip_code}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 2 documents in collection 'Top10StartStationsCopy' with ZIP code 60601 to population 15083\n",
      "Updated 2 documents in collection 'Top10StartStationsCopy' with ZIP code 60654 to population 20022\n",
      "Updated 1 documents in collection 'Top10StartStationsCopy' with ZIP code 60657 to population 70958\n",
      "Updated 0 documents in collection 'Top10StartStationsCopy' with ZIP code 60610 to population 40548\n",
      "Updated 1 documents in collection 'Top10StartStationsCopy' with ZIP code 60612 to population 33735\n",
      "Updated 1 documents in collection 'Top10StartStationsCopy' with ZIP code 60605 to population 29060\n",
      "Updated 0 documents in collection 'Top10StartStationsCopy' with ZIP code 60611 to population 33224\n",
      "Updated 1 documents in collection 'Top10StartStationsCopy' with ZIP code 60614 to population 71954\n",
      "Updated 2 documents in collection 'Top10EndStationsCopy' with ZIP code 60601 to population 15083\n",
      "Updated 1 documents in collection 'Top10EndStationsCopy' with ZIP code 60654 to population 20022\n",
      "Updated 1 documents in collection 'Top10EndStationsCopy' with ZIP code 60657 to population 70958\n",
      "Updated 2 documents in collection 'Top10EndStationsCopy' with ZIP code 60610 to population 40548\n",
      "Updated 0 documents in collection 'Top10EndStationsCopy' with ZIP code 60612 to population 33735\n",
      "Updated 0 documents in collection 'Top10EndStationsCopy' with ZIP code 60605 to population 29060\n",
      "Updated 2 documents in collection 'Top10EndStationsCopy' with ZIP code 60611 to population 33224\n",
      "Updated 2 documents in collection 'Top10EndStationsCopy' with ZIP code 60614 to population 71954\n"
     ]
    }
   ],
   "source": [
    "# Add population data back with Top 10 Start Stations and Top 10 End Stations collections\n",
    "\n",
    "# Connect to collections\n",
    "start_stations_collection = db2.Top10StartStationsCopy\n",
    "end_stations_collection = db2.Top10EndStationsCopy\n",
    "\n",
    "# Retrieve the population data for each ZIP code from the census API\n",
    "def get_population_data(api_key_census, zip_codes):\n",
    "    population_data = {}\n",
    "    for zip_code in zip_codes:\n",
    "        # Construct the API request URL\n",
    "        response = requests.get(\n",
    "            f\"https://api.census.gov/data/2019/acs/acs5\",\n",
    "            params={\n",
    "                'get': 'B01003_001E',\n",
    "                'for': f'zip code tabulation area:{zip_code}',\n",
    "                'in': 'state:17',  # Illinois state code\n",
    "                'key': api_key_census\n",
    "            }\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # Extract the population count and update the population_data dictionary\n",
    "            population_data[zip_code] = int(data[1][0])\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data for ZIP code {zip_code}: {response.text}\")\n",
    "    \n",
    "    return population_data\n",
    "\n",
    "# Function to update the station documents with population data\n",
    "def update_stations_with_population(collection, population_data):\n",
    "    for zip_code, population in population_data.items():\n",
    "        # Update documents in the collection with the matching ZIP code\n",
    "        result = collection.update_many(\n",
    "            {'zip_code': zip_code},\n",
    "            {'$set': {'population': population}}\n",
    "        )\n",
    "        print(f\"Updated {result.modified_count} documents in collection '{collection.name}' with ZIP code {zip_code} to population {population}\")\n",
    "\n",
    "# Retrieve a list of unique ZIP codes from both collections, safely checking for the 'zip_code' field\n",
    "relevant_zip_codes = []\n",
    "for collection in [start_stations_collection, end_stations_collection]:\n",
    "    for doc in collection.find():\n",
    "        zip_code = doc.get('zip_code')\n",
    "        if zip_code:\n",
    "            relevant_zip_codes.append(zip_code)\n",
    "relevant_zip_codes = list(set(relevant_zip_codes))  # Remove duplicates\n",
    "\n",
    "# Retrieve population data for the relevant ZIP codes\n",
    "population_data = get_population_data(api_key_census, relevant_zip_codes)\n",
    "\n",
    "# Update the collections with the population data\n",
    "update_stations_with_population(start_stations_collection, population_data)\n",
    "update_stations_with_population(end_stations_collection, population_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 71269, 'latitude': 41.880958, 'longitude': -87.616743, 'zip_code': '60601', 'population': 15083}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 39251, 'latitude': 41.867888, 'longitude': -87.623041, 'zip_code': '60605', 'population': 29060}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 37698, 'latitude': 41.897448, 'longitude': -87.628722, 'zip_code': '60654', 'population': 20022}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 37208, 'latitude': 41.869265218438194, 'longitude': -87.67373085021973, 'zip_code': '60612', 'population': 33735}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34508, 'latitude': 41.897448, 'longitude': -87.628722}\n",
      "{'_id': 'Millennium Park', 'count': 32849, 'latitude': 41.8810317, 'longitude': -87.62408432, 'zip_code': '60601', 'population': 15083}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32560, 'latitude': 41.920771, 'longitude': -87.663712, 'zip_code': '60614', 'population': 71954}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 31614, 'latitude': 41.893992, 'longitude': -87.629318, 'zip_code': '60654', 'population': 20022}\n",
      "{'_id': 'Theater on the Lake', 'count': 31283, 'latitude': 41.926277, 'longitude': -87.630834, 'zip_code': '60657', 'population': 70958}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28978, 'latitude': 41.893992, 'longitude': -87.629318}\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure the collections were copied correctly\n",
    "collection_name = 'Top10StartStationsCopy'\n",
    "collection = db2[collection_name]\n",
    "# The find() method without any parameters will return all documents in the collection\n",
    "documents = collection.find()\n",
    "\n",
    "# Print each document\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 72540, 'latitude': 41.892278, 'longitude': -87.612043, 'zip_code': '60611', 'population': 33224}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 40563, 'latitude': 41.911722, 'longitude': -87.626804, 'zip_code': '60614', 'population': 71954}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 38500, 'latitude': 41.880958, 'longitude': -87.616743, 'zip_code': '60601', 'population': 15083}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 38279, 'latitude': 41.90096039, 'longitude': -87.62377664, 'zip_code': '60611', 'population': 33224}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 34688, 'latitude': 41.912133, 'longitude': -87.634656, 'zip_code': '60614', 'population': 71954}\n",
      "{'_id': 'Millennium Park', 'count': 33705, 'latitude': 41.8810317, 'longitude': -87.62408432, 'zip_code': '60601', 'population': 15083}\n",
      "{'_id': 'Clark St & Elm St', 'count': 32227, 'latitude': 41.902973, 'longitude': -87.63128, 'zip_code': '60610', 'population': 40548}\n",
      "{'_id': 'Theater on the Lake', 'count': 31672, 'latitude': 41.926277, 'longitude': -87.630834, 'zip_code': '60657', 'population': 70958}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 30450, 'latitude': 41.88917683258, 'longitude': -87.6385057718, 'zip_code': '60654', 'population': 20022}\n",
      "{'_id': 'Wells St & Elm St', 'count': 28346, 'latitude': 41.903222, 'longitude': -87.634324, 'zip_code': '60610', 'population': 40548}\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure the collections were copied correctly\n",
    "collection_name = 'Top10EndStationsCopy'\n",
    "collection = db2[collection_name]\n",
    "# The find() method without any parameters will return all documents in the collection\n",
    "documents = collection.find()\n",
    "\n",
    "# Print each document\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'population'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\alici\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\alici\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alici\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'population'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alici\\Desktop\\Project-3-Divvying-in-the-Rain\\Census.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alici/Desktop/Project-3-Divvying-in-the-Rain/Census.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m df_pandas \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(mongo_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alici/Desktop/Project-3-Divvying-in-the-Rain/Census.ipynb#X32sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Calculate Pearson correlation coefficient and p-value\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/alici/Desktop/Project-3-Divvying-in-the-Rain/Census.ipynb#X32sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m correlation_coefficient, p_value \u001b[39m=\u001b[39m pearsonr(df_pandas[\u001b[39m'\u001b[39;49m\u001b[39mpopulation\u001b[39;49m\u001b[39m'\u001b[39;49m], df_pandas[\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alici/Desktop/Project-3-Divvying-in-the-Rain/Census.ipynb#X32sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Visualize the relationship with a scatter plot\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alici/Desktop/Project-3-Divvying-in-the-Rain/Census.ipynb#X32sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m plt\u001b[39m.\u001b[39mscatter(df_pandas[\u001b[39m'\u001b[39m\u001b[39mpopulation\u001b[39m\u001b[39m'\u001b[39m], df_pandas[\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\alici\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\alici\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'population'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the MongoDB connection\n",
    "mongo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
