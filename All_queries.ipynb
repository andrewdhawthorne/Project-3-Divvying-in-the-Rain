{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Divvy Bike Data: \n",
    "\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202201-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202202-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202203-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202204-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202205-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202206-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202207-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202208-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202209-divvy-publictripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202210-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202211-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline  202212-divvy-tripdata.csv<br>\n",
    "\n",
    "### Import Weather Data: \n",
    "please run OpenWeather.ipynb first to create weather_daily.csv file and then import using the mongoimport statement below\n",
    "\n",
    "mongoimport --type csv -d chicago_bikes -c weather_daily --headerline weather_daily.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pymongo\n",
    "from pymongo import MongoClient, UpdateOne\n",
    "import json\n",
    "from calendar import monthrange\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of MongoClient\n",
    "mongo = MongoClient(port=27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'autosaurus', 'classDB', 'config', 'epa', 'fruits_db', 'gardenDB', 'local', 'met', 'mongodbVSCodePlaygroundDB', 'petsitly_marketing', 'travel_db', 'uk_food']\n"
     ]
    }
   ],
   "source": [
    "# check our list of collections\n",
    "print(mongo.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the database to a variable name\n",
    "db = mongo.chicago_bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# review the collections in our new database\n",
    "print(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review a document in the customer_list collection\n",
    "print(db.divvy_ridedata.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign divvy_rides and weather_daily collections to variables for later use\n",
    "divvy_rides = db['divvy_ridedata']\n",
    "weather_daily = db['weather_daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert precipitation field value to inches (currently in mm) in weather_daily collection\n",
    "# Conversion factor: 1 mm = 0.03937 inches\n",
    "mm_to_inches = 0.03937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through documents and update values\n",
    "for document in weather_daily.find():\n",
    "    size_mm = document.get(\"precipitation\")\n",
    "    if size_mm is not None:\n",
    "        size_inches = size_mm * mm_to_inches\n",
    "        # Update the document with the new size value in inches\n",
    "        weather_daily.update_one({\"_id\": document[\"_id\"]}, {\"$set\": {\"prcp_inches\": size_inches}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review a document in the weather_daily collection to confirm update\n",
    "print(db.weather_daily.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'size_inches' field as it has been replaced with 'prcp_inches' and values match \n",
    "# Specify the field you want to drop\n",
    "field_to_drop = \"size_inches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update documents to unset the specified field\n",
    "weather_daily.update_many({}, {\"$unset\": {field_to_drop: 1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review a document in the weather_daily collection to confirm drop\n",
    "print(db.weather_daily.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the threshold value for significant precipitation comparison \n",
    "threshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update documents to add the new field \"sig_prcp\"\n",
    "# Add a new field 'sig_prcp' and populate 'yes' values if 'prcp_inches' is greather than or equal .1 inches\n",
    "weather_daily.update_many(\n",
    "    {\"prcp_inches\": {\"$gte\": threshold}},\n",
    "    {\"$set\": {\"sig_prcp\": \"yes\"}}\n",
    ")\n",
    "\n",
    "weather_daily.update_many(\n",
    "    {\"prcp_inches\": {\"$lt\": threshold}},\n",
    "    {\"$set\": {\"sig_prcp\": \"no\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review a document in the weather_daily collection to confirm update\n",
    "print(db.weather_daily.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update documents to add the new field \"avg_temp\"\n",
    "weather_daily.update_many(\n",
    "    {},\n",
    "    [\n",
    "        {\n",
    "            \"$set\": {\n",
    "                \"avg_temp\": {\n",
    "                    \"$avg\": [\"$morning_temp\", \"$afternoon_temp\", \"$evening_temp\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review a document in the weather_daily collection to confirm update\n",
    "print(db.weather_daily.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform bulk update operation on 'started_at' field to split date and time into two separate fields\n",
    "documents = divvy_rides.find({})\n",
    "bulk_updates = []\n",
    "\n",
    "for document in documents:\n",
    "    original_value = document[\"started_at\"]\n",
    "    parts = original_value.split(\" \")\n",
    "    date_part = parts[0]\n",
    "    time_part = parts[1]\n",
    "    bulk_updates.append(\n",
    "        pymongo.UpdateOne(\n",
    "            {\"_id\": document[\"_id\"]},\n",
    "            {\n",
    "                \"$set\": {\n",
    "                    \"started_at_date\": date_part,\n",
    "                    \"started_at_time\": time_part\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Execute bulk write operations\n",
    "divvy_rides.bulk_write(bulk_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform bulk update operation on 'ended_at' field to split date and time into two separate fields\n",
    "documents = divvy_rides.find({})\n",
    "bulk_updates = []\n",
    "\n",
    "for document in documents:\n",
    "    original_value = document[\"ended_at\"]\n",
    "    parts = original_value.split(\" \")\n",
    "    date_part = parts[0]\n",
    "    time_part = parts[1]\n",
    "    bulk_updates.append(\n",
    "        pymongo.UpdateOne(\n",
    "            {\"_id\": document[\"_id\"]},\n",
    "            {\n",
    "                \"$set\": {\n",
    "                    \"ended_at_date\": date_part,\n",
    "                    \"ended_at_time\": time_part\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Execute bulk write operations\n",
    "divvy_rides.bulk_write(bulk_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign an index to each collection for use in pipeline merging of the two collections\n",
    "divvy_rides.create_index([(\"started_at_date\", 1)])\n",
    "weather_daily.create_index([(\"date\", 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and run a pipeling to merge divvy_rides and weather_daily collections into divvy_ridedata_merged collection\n",
    "pipeline = [\n",
    "    {\n",
    "        '$lookup': {\n",
    "            'from': 'weather_daily',\n",
    "            'localField': 'started_at_date',\n",
    "            'foreignField': 'date',\n",
    "            'as': 'weather_data'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$unwind': {\n",
    "            'path': '$weather_data',\n",
    "            'preserveNullAndEmptyArrays': True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$merge': {\n",
    "            'into': 'divvy_ridedata_merged',  # Replace with your new collection name\n",
    "            'whenMatched': 'merge',  # Merge documents with matching _id fields\n",
    "            'whenNotMatched': 'insert'  # Insert documents that don't match\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "divvy_rides.aggregate(pipeline)\n",
    "print(\"Update completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the new merged collection to a variable and print a document from the collection\n",
    "divvy_ridedata_merged = db['divvy_ridedata_merged']\n",
    "divvy_ridedata_merged.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review the collections in our new database\n",
    "print(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to create a collection that contains start and end station names\n",
    "pipeline = [\n",
    "         {\"$match\": {\"start_station_name\": {\"$exists\": True, \"$ne\": \"\"}, \n",
    "                     \"end_station_name\":{\"$exists\": True, \"$ne\": \"\"}}},\n",
    "\n",
    "         {\"$out\": \"withStationName\"}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(divvy_ridedata_merged.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to make sure that collections is updated\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there are any documents without start or end station names\n",
    "print(db.withStationName.find_one({\"start_station_name\":\"\"}))\n",
    "print(db.withStationName.find_one({\"end_station_name\":\"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to create a collection that doesn't contain start and end station names\n",
    "pipeline = [\n",
    "         {\"$match\": {\"start_station_name\": {\"$exists\": True, \"$eq\": \"\"}, \n",
    "                     \"end_station_name\":{\"$exists\": True, \"$eq\": \"\"}}},\n",
    "\n",
    "         {\"$out\": \"withoutStationName\"}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(divvy_ridedata_merged.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#Check to see that the collection was added\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m db\u001b[39m.\u001b[39mlist_collection_names()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "#Check to see that the collection was added\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there are any documents without start or end station names\n",
    "print(db.withoutStationName.find_one({\"start_station_name\":{\"$ne\":\"\"}}))\n",
    "print(db.withoutStationName.find_one({\"end_station_name\":{\"$ne\":\"\"}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to find top ten start stations \n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$start_station_name\",\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"latitude\": {\"$first\": \"$end_lat\"},\n",
    "            \"longitude\": {\"$first\": \"$end_lng\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"count\": -1}\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 10\n",
    "    },\n",
    "    {   \"$out\": \"Top10StartStations\"\n",
    "}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(withStation.aggregate(pipeline))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign collection to a variable\n",
    "Top10StartStations = db['Top10StartStations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see that the collection was added\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull a document from the collection\n",
    "Top10StartStations.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to find top ten end stations \n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$end_station_name\",\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"latitude\": {\"$first\": \"$end_lat\"},\n",
    "            \"longitude\": {\"$first\": \"$end_lng\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"count\": -1}\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 10\n",
    "    },\n",
    "    {   \"$out\": \"Top10EndStations\"\n",
    "}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(withStation.aggregate(pipeline))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to a variable\n",
    "Top10EndStations = db['Top10EndStations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline query to find the top ten bike routes (by start and end station)\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": { \"Start Station\": \"$start_station_name\", \"End Station\": \"$end_station_name\"},\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"start latitude\": {\"$first\": \"$start_lat\"},\n",
    "            \"start longitude\": {\"$first\": \"$start_lng\"},\n",
    "            \"end latitude\": {\"$first\": \"$end_lat\"},\n",
    "            \"end longitude\": {\"$first\": \"$end_lng\"}\n",
    "        }\n",
    "    },\n",
    "    {\"$sort\": {\"count\": -1}\n",
    "},\n",
    "    {\n",
    "        \"$limit\": 10\n",
    "},\n",
    "    {   \"$out\": \"Top10Routes\"\n",
    "}\n",
    "]\n",
    "# Perform the aggregation\n",
    "result = list(withStation.aggregate(pipeline))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to a variable\n",
    "Top10Routes = db['Top10Routes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see that the collection was added\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review a document in the collection \n",
    "Top10Routes.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline query to find docouments that have lat/long  \n",
    "pipeline = [\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"$and\": [\n",
    "                { \"start_lat\": { \"$ne\": \"\" } },\n",
    "                { \"start_lng\": { \"$ne\": \"\" } },\n",
    "                { \"end_lat\": { \"$ne\": \"\" } },\n",
    "                { \"end_lng\": { \"$ne\": \"\" } }\n",
    "            ]\n",
    "        }\n",
    "    }, \n",
    "    {\"$out\": \"withLatLong\"}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(divvy_ridedata_merged.aggregate(pipeline))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the collection to a variable\n",
    "withLatLong = db['withLatLong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline query to find distance of each route in descending order by length  \n",
    "pipeline = [\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"start_lat\": { \"$toDouble\": \"$start_lat\" },\n",
    "            \"start_lng\": { \"$toDouble\": \"$start_lng\" },\n",
    "            \"end_lat\": { \"$toDouble\": \"$end_lat\" },\n",
    "            \"end_lng\": { \"$toDouble\": \"$end_lng\" }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"distance\": {\n",
    "                \"$sqrt\": {\n",
    "                    \"$add\": [\n",
    "                        {\n",
    "                            \"$pow\": [\n",
    "                                { \"$subtract\": [\"$end_lat\", \"$start_lat\"] },\n",
    "                                2\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            \"$pow\": [\n",
    "                                {\n",
    "                                    \"$multiply\": [\n",
    "                                        { \"$subtract\": [\"$end_lng\", \"$start_lng\"] },\n",
    "                                        { \"$cos\": { \"$avg\": [\"$start_lat\", \"$end_lat\"] } }\n",
    "                                    ]\n",
    "                                },\n",
    "                                2\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"distance\": -1}\n",
    "    },\n",
    "    {\"$out\": \"RouteDistance\"}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(withLatLong.aggregate(pipeline))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to a variable\n",
    "RouteDistance = db['RouteDistance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of documents in the collection \n",
    "print(RouteDistance.count_documents({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first 10 documents\n",
    "documents = RouteDistance.find().sort(\"distance\", -1).limit(10)\n",
    "\n",
    "# Print the documents\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregation pipeline to pull rides by month \n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": {\n",
    "                \"year\": {\"$year\": {\"$toDate\": \"$started_at\"}},\n",
    "                \"month\": {\"$month\": {\"$toDate\": \"$started_at\"}}\n",
    "            },\n",
    "            \"total_rides\": {\"$sum\": 1}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"year\": \"$_id.year\",\n",
    "            \"month\": \"$_id.month\",\n",
    "            \"total_rides\": 1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"year\": 1, \"month\": 1}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Execute the aggregation pipeline and write to a new collection\n",
    "divvy_rides_by_month = db[\"divvy_rides_by_month\"]\n",
    "divvy_rides_by_month.drop()  # Drop the collection\n",
    "aggregated_result = divvy_ridedata_merged.aggregate(pipeline, allowDiskUse=True, collation=None)\n",
    "\n",
    "for doc in aggregated_result:\n",
    "    divvy_rides_by_month.insert_one(doc)\n",
    "\n",
    "print(\"Aggregation result has been written to the new collection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregation pipeline to define divvy rides by season \n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": {\n",
    "                \"year\": \"$year\",\n",
    "                \"season\": {\n",
    "                    \"$switch\": {\n",
    "                        \"branches\": [\n",
    "                            {\"case\": {\"$in\": [\"$month\", [3, 4, 5]]}, \"then\": \"Spring\"},\n",
    "                            {\"case\": {\"$in\": [\"$month\", [6, 7, 8]]}, \"then\": \"Summer\"},\n",
    "                            {\"case\": {\"$in\": [\"$month\", [9, 10, 11]]}, \"then\": \"Autumn\"},\n",
    "                            {\"case\": {\"$in\": [\"$month\", [12, 1, 2]]}, \"then\": \"Winter\"}\n",
    "                        ],\n",
    "                        \"default\": \"Unknown\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"total_rides\": {\"$sum\": \"$total_rides\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"_id.year\": 1, \"_id.season\": 1}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Execute the aggregation pipeline\n",
    "divvy_rides_by_season = db[\"divvy_rides_by_season\"]\n",
    "divvy_rides_by_season.drop()  # Drop the collection\n",
    "aggregated_result = list(divvy_rides_by_month.aggregate(pipeline, allowDiskUse=True, collation=None))\n",
    "\n",
    "# Insert the aggregated documents into the new collection\n",
    "for doc in aggregated_result:\n",
    "    print(\"Inserting document:\", doc)\n",
    "    divvy_rides_by_season.insert_one(doc)\n",
    "\n",
    "print(\"Aggregation by season result has been written to the new collection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson import ObjectId\n",
    "\n",
    "# Get distinct station names along with start_lat and start_lng\n",
    "distinct_station_data = db[\"withStationName\"].aggregate([\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$start_station_name\",\n",
    "            \"start_lat\": {\"$first\": \"$start_lat\"},\n",
    "            \"start_lng\": {\"$first\": \"$start_lng\"}\n",
    "        }\n",
    "    }\n",
    "])\n",
    "\n",
    "collection_name = \"distinct_station_names\"\n",
    "station_names = db[collection_name]\n",
    "\n",
    "station_name_documents = []\n",
    "for data in distinct_station_data:\n",
    "    station_name_documents.append({\n",
    "        \"start_station_name\": data[\"_id\"],\n",
    "        \"start_lat\": data[\"start_lat\"],\n",
    "        \"start_lng\": data[\"start_lng\"],\n",
    "        \"_id\": str(ObjectId())\n",
    "    })\n",
    "\n",
    "station_names.insert_many(station_name_documents)\n",
    "\n",
    "print(f\"{len(station_name_documents)} distinct station names imported into '{collection_name}' collection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find a station name from the collection\n",
    "station_names.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to create a collection that contains rides on days with significant precipitation\n",
    "pipeline = [\n",
    "         {\"$match\": {\"weather_data.sig_prcp\": {\"$exists\": True, \"$eq\": \"yes\"},\n",
    "                     }},\n",
    "         {\"$out\": \"sig_prcp_yes\"}\n",
    "         \n",
    "]\n",
    "# Perform the aggregation\n",
    "result = list(divvy_ridedata_merged.aggregate(pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to a variable\n",
    "sig_prcp_yes = db[\"sig_prcp_yes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_prcp_yes.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to create a collection that contains rides on days without significant precipitation\n",
    "pipeline = [\n",
    "         {\"$match\": {\"weather_data.sig_prcp\": {\"$exists\": True, \"$eq\": \"no\"},\n",
    "                     }},\n",
    "         {\"$out\": \"sig_prcp_no\"}\n",
    "         \n",
    "]\n",
    "# Perform the aggregation\n",
    "result = list(divvy_ridedata_merged.aggregate(pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to a variable\n",
    "sig_prcp_no = db[\"sig_prcp_no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_prcp_no.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new collection that shows average daily rides per month with precipitation \n",
    "\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": {\n",
    "                \"year\": {\"$year\": {\"$toDate\": \"$started_at\"}},\n",
    "                \"month\": {\"$month\": {\"$toDate\": \"$started_at\"}}\n",
    "            },\n",
    "            \"total_rides\": {\"$sum\": 1}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"year\": \"$_id.year\",\n",
    "            \"month\": \"$_id.month\",\n",
    "            \"total_rides\": 1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"year\": 1, \"month\": 1}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Execute the aggregation pipeline and write to a new collection\n",
    "sig_prcp_yes_month = db[\"sig_prcp_yes_month\"]\n",
    "#divvy_rides_by_month = db[\"divvy_rides_by_month\"]\n",
    "sig_prcp_yes_month.drop()  # Drop the collection\n",
    "aggregated_result = sig_prcp_yes.aggregate(pipeline, allowDiskUse=True, collation=None)\n",
    "\n",
    "for doc in aggregated_result:\n",
    "    sig_prcp_yes_month.insert_one(doc)\n",
    "\n",
    "# Function to insert number of days and sig_prcp count for each month\n",
    "def update_num_days_and_sig_prcp_count(year, month):\n",
    "    _, num_days = monthrange(year, month)\n",
    "    query = {'year': year, 'month': month}\n",
    "    update_query = {'$set': {'num_days': num_days}}\n",
    "    sig_prcp_yes_month.update_one(query, update_query)\n",
    "\n",
    "    # Count the number of days with sig_prcp = 'no' for the given month\n",
    "# Count the number of days with sig_prcp = 'no' for the given month\n",
    "    sig_prcp_count = weather_daily.count_documents({\n",
    "        'date': {'$regex': f'^{year:04d}-{month:02d}'},  # Match the year and month in the date field\n",
    "        'sig_prcp': 'yes'\n",
    "    })\n",
    "    update_query = {'$set': {'sig_prcp_count': sig_prcp_count}}\n",
    "    sig_prcp_yes_month.update_one(query, update_query)\n",
    "\n",
    "    # Calculate average rides per day\n",
    "    total_rides = sig_prcp_yes_month.find_one(query)['total_rides']\n",
    "    sig_prcp_yes_month.update_one(query, update_query)\n",
    "\n",
    "    # Calculate and update average rides per day with no significant precipitation\n",
    "    query = {'year': 2022, 'month': month}\n",
    "    document = sig_prcp_yes_month.find_one(query)\n",
    "    \n",
    "    if document['sig_prcp_count'] > 0:  # To avoid division by zero\n",
    "        average_rides_per_day = document['total_rides'] / document['sig_prcp_count']\n",
    "        update_query = {'$set': {'average_rides_per_day': average_rides_per_day}}\n",
    "        sig_prcp_yes_month.update_one(query, update_query)\n",
    "\n",
    "# Loop through each month in the year 2022\n",
    "for month in range(1, 13):\n",
    "    update_num_days_and_sig_prcp_count(2022, month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new collection that shows average daily rides per month with no precipitation \n",
    "\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": {\n",
    "                \"year\": {\"$year\": {\"$toDate\": \"$started_at\"}},\n",
    "                \"month\": {\"$month\": {\"$toDate\": \"$started_at\"}}\n",
    "            },\n",
    "            \"total_rides\": {\"$sum\": 1}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"year\": \"$_id.year\",\n",
    "            \"month\": \"$_id.month\",\n",
    "            \"total_rides\": 1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"year\": 1, \"month\": 1}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Execute the aggregation pipeline and write to a new collection\n",
    "sig_prcp_no_month = db[\"sig_prcp_no_month\"]\n",
    "#divvy_rides_by_month = db[\"divvy_rides_by_month\"]\n",
    "sig_prcp_no_month.drop()  # Drop the collection\n",
    "aggregated_result = sig_prcp_no.aggregate(pipeline, allowDiskUse=True, collation=None)\n",
    "\n",
    "for doc in aggregated_result:\n",
    "    sig_prcp_no_month.insert_one(doc)\n",
    "\n",
    "def update_num_days_and_sig_prcp_count(year, month):\n",
    "    _, num_days = monthrange(year, month)\n",
    "    query = {'year': year, 'month': month}\n",
    "    update_query = {'$set': {'num_days': num_days}}\n",
    "    sig_prcp_no_month.update_one(query, update_query)\n",
    "\n",
    "    # Count the number of days with sig_prcp = 'no' for the given month\n",
    "    sig_prcp_count = weather_daily.count_documents({\n",
    "        'date': {'$regex': f'^{year:04d}-{month:02d}'},\n",
    "        'sig_prcp': 'no'\n",
    "    })\n",
    "    update_query = {'$set': {'sig_prcp_count': sig_prcp_count}}\n",
    "    sig_prcp_no_month.update_one(query, update_query)\n",
    "\n",
    "    # Calculate average rides per day\n",
    "    document = sig_prcp_no_month.find_one(query)\n",
    "    \n",
    "    if document['sig_prcp_count'] > 0:\n",
    "        total_rides = document['total_rides']\n",
    "        average_rides_per_day = total_rides / document['sig_prcp_count']\n",
    "        update_query = {'$set': {'average_rides_per_day': average_rides_per_day}}\n",
    "        sig_prcp_no_month.update_one(query, update_query)\n",
    "\n",
    "# Loop through each month in the year 2022\n",
    "for month in range(1, 13):\n",
    "    update_num_days_and_sig_prcp_count(2022, month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new collection to store documents with string _id\n",
    "sig_prcp_no_month_string.drop()\n",
    "sig_prcp_no_month_string = db[\"sig_prcp_no_month_with_string_id\"]\n",
    "\n",
    "# Iterate through the documents in the original collection\n",
    "for document in sig_prcp_no_month.find({}):\n",
    "    document_id = document['_id']\n",
    "    string_id = str(document_id)\n",
    "    \n",
    "    # Create a new document with the string _id and other fields\n",
    "    new_document = {\n",
    "        '_id': string_id,\n",
    "        'year': document['year'],\n",
    "        'month': document['month'],\n",
    "        'total_rides': document['total_rides'],\n",
    "        'num_days': document['num_days'],\n",
    "        'sig_prcp_count': document['sig_prcp_count'],\n",
    "        'average_rides_per_day': document['average_rides_per_day']\n",
    "        # Include other fields from the original document\n",
    "    }\n",
    "    \n",
    "    # Insert the new document into the new collection\n",
    "    sig_prcp_no_month_string.insert_one(new_document)\n",
    "\n",
    "print(\"Documents with string _id inserted into the new collection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new collection to store documents with string _id\n",
    "sig_prcp_yes_month_string.drop()\n",
    "sig_prcp_yes_month_string = db[\"sig_prcp_yes_month_with_string_id\"]\n",
    "\n",
    "# Iterate through the documents in the original collection\n",
    "for document in sig_prcp_yes_month.find({}):\n",
    "    document_id = document['_id']\n",
    "    string_id = str(document_id)\n",
    "    \n",
    "    # Create a new document with the string _id and other fields\n",
    "    new_document = {\n",
    "        '_id': string_id,\n",
    "        'year': document['year'],\n",
    "        'month': document['month'],\n",
    "        'total_rides': document['total_rides'],\n",
    "        'num_days': document['num_days'],\n",
    "        'sig_prcp_count': document['sig_prcp_count'],\n",
    "        'average_rides_per_day': document['average_rides_per_day']\n",
    "        # Include other fields from the original document\n",
    "    }\n",
    "    \n",
    "    # Insert the new document into the new collection\n",
    "    sig_prcp_yes_month_string.insert_one(new_document)\n",
    "\n",
    "print(\"Documents with string _id inserted into the new collection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro_python_requirements_windo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
