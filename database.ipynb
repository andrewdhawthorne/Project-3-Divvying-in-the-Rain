{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Divvy Bike Data: \n",
    "\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202201-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202202-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202203-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202204-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202205-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202206-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202207-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202208-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202209-divvy-publictripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202210-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202211-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline  202212-divvy-tripdata.csv<br>\n",
    "\n",
    "### Import Weather Data: \n",
    "mongoimport --type csv -d chicago_bikes -c weather_daily --headerline weather_daily.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient, UpdateOne\n",
    "import json\n",
    "\n",
    "# Adding for query to find top ten stations \n",
    "#from pymongo.collection import Collection\n",
    "#from pymongo.aggregation import Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of MongoClient\n",
    "mongo = MongoClient(port=27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check our list of collections\n",
    "print(mongo.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the database to a variable name\n",
    "db = mongo.chicago_bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review the collections in our new database\n",
    "print(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review a document in the customer_list collection\n",
    "print(db.divvy_ridedata.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy_rides = db['divvy_ridedata']\n",
    "weather_daily = db['weather_daily']\n",
    "withStation = db['withStationName']\n",
    "withoutStation = db['withoutStationName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(divvy_rides.count_documents({}))\n",
    "print(weather_daily.count_documents({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = divvy_rides.find({})\n",
    "bulk_updates = []\n",
    "\n",
    "for document in documents:\n",
    "    original_value = document[\"started_at\"]\n",
    "    parts = original_value.split(\" \")\n",
    "    date_part = parts[0]\n",
    "    time_part = parts[1]\n",
    "    bulk_updates.append(\n",
    "        pymongo.UpdateOne(\n",
    "            {\"_id\": document[\"_id\"]},\n",
    "            {\n",
    "                \"$set\": {\n",
    "                    \"started_at_date\": date_part,\n",
    "                    \"started_at_time\": time_part\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Execute bulk write operations\n",
    "divvy_rides.bulk_write(bulk_updates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = divvy_rides.find({})\n",
    "bulk_updates = []\n",
    "\n",
    "for document in documents:\n",
    "    original_value = document[\"ended_at\"]\n",
    "    parts = original_value.split(\" \")\n",
    "    date_part = parts[0]\n",
    "    time_part = parts[1]\n",
    "    bulk_updates.append(\n",
    "        pymongo.UpdateOne(\n",
    "            {\"_id\": document[\"_id\"]},\n",
    "            {\n",
    "                \"$set\": {\n",
    "                    \"ended_at_date\": date_part,\n",
    "                    \"ended_at_time\": time_part\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Execute bulk write operations\n",
    "divvy_rides.bulk_write(bulk_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.divvy_ridedata.find_one())\n",
    "print(db.weather_daily.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy_rides.create_index([(\"started_at_date\", 1)])\n",
    "weather_daily.create_index([(\"date\", 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        '$lookup': {\n",
    "            'from': 'weather_daily',\n",
    "            'localField': 'started_at_date',\n",
    "            'foreignField': 'date',\n",
    "            'as': 'weather_data'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$unwind': {\n",
    "            'path': '$weather_data',\n",
    "            'preserveNullAndEmptyArrays': True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$merge': {\n",
    "            'into': 'divvy_ridedata_merged',  # Replace with your new collection name\n",
    "            'whenMatched': 'merge',  # Merge documents with matching _id fields\n",
    "            'whenNotMatched': 'insert'  # Insert documents that don't match\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "divvy_rides.aggregate(pipeline)\n",
    "print(\"Update completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the database and collection\n",
    "collection = db[\"divvy_ridedata_merged\"]  # Replace with your collection name\n",
    "\n",
    "# Count the documents in the collection\n",
    "document_count = collection.count_documents({})\n",
    "print(\"Total number of documents:\", document_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy_ridedata_merged = db['divvy_ridedata_merged']\n",
    "divvy_ridedata_merged.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review the collections in our new database\n",
    "print(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to create a collection that contains start and end station names\n",
    "pipeline = [\n",
    "         {\"$match\": {\"start_station_name\": {\"$exists\": True, \"$ne\": \"\"}, \n",
    "                     \"end_station_name\":{\"$exists\": True, \"$ne\": \"\"}}},\n",
    "\n",
    "         {\"$out\": \"withStationName\"}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(divvy_ridedata_merged.aggregate(pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to make sure that collections is updated\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there are any documents without start or end station names\n",
    "print(db.withStationName.find_one({\"start_station_name\":\"\"}))\n",
    "print(db.withStationName.find_one({\"end_station_name\":\"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to create a collection that doesn't contain start and end station names\n",
    "pipeline = [\n",
    "         {\"$match\": {\"start_station_name\": {\"$exists\": True, \"$eq\": \"\"}, \n",
    "                     \"end_station_name\":{\"$exists\": True, \"$eq\": \"\"}}},\n",
    "\n",
    "         {\"$out\": \"withoutStationName\"}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(divvy_ridedata_merged.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there are any documents without start or end station names\n",
    "print(db.withoutStationName.find_one({\"start_station_name\":{\"$ne\":\"\"}}))\n",
    "print(db.withoutStationName.find_one({\"end_station_name\":{\"$ne\":\"\"}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to find top ten start stations \n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$start_station_name\",\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"latitude\": {\"$first\": \"$end_lat\"},\n",
    "            \"longitude\": {\"$first\": \"$end_lng\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"count\": -1}\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 10\n",
    "    },\n",
    "    {   \"$out\": \"Top10StartStations\"\n",
    "}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(withStation.aggregate(pipeline))\n",
    "\n",
    "# Assign collection to a variable\n",
    "Top10StartStations = db['Top10StartStations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see that the collection was added\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top10StartStations.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to find top ten end stations \n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$end_station_name\",\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"latitude\": {\"$first\": \"$end_lat\"},\n",
    "            \"longitude\": {\"$first\": \"$end_lng\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"count\": -1}\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 10\n",
    "    },\n",
    "    {   \"$out\": \"Top10EndStations\"\n",
    "}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(withStation.aggregate(pipeline))\n",
    "\n",
    "# Assign to a variable\n",
    "Top10EndStations = db['Top10EndStations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline query to find the top ten bike routes (by start and end station)\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": { \"Start Station\": \"$start_station_name\", \"End Station\": \"$end_station_name\"},\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"latitude\": {\"$first\": \"$end_lat\"},\n",
    "            \"longitude\": {\"$first\": \"$end_lng\"}\n",
    "        }\n",
    "    },\n",
    "    {\"$sort\": {\"count\": -1}\n",
    "},\n",
    "    {\n",
    "        \"$limit\": 10\n",
    "},\n",
    "    {   \"$out\": \"Top10Routes\"\n",
    "}\n",
    "]\n",
    "# Perform the aggregation\n",
    "result = list(withStation.aggregate(pipeline))\n",
    "\n",
    "# Assign to a variable\n",
    "Top10Routes = db['Top10Routes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a pipeline query to find the top ten bike routes (by start and end lat/lon)\n",
    "# pipeline = [\n",
    "#     {\n",
    "#         \"$group\": {\n",
    "#             \"_id\": { \"Start Station\": \"$start_station_name\", \"End Station\": \"$end_station_name\"},\n",
    "#             \"count\": {\"$sum\": 1},\n",
    "#             \"latitude\": {\"$first\": \"$end_lat\"},\n",
    "#             \"longitude\": {\"$first\": \"$end_lng\"}\n",
    "#         }\n",
    "#     },\n",
    "#     {\"$sort\": {\"count\": -1}\n",
    "# },\n",
    "#     {\n",
    "#         \"$limit\": 10\n",
    "# },\n",
    "#     {   \"$out\": \"Top10Routes\"\n",
    "# }\n",
    "# ]\n",
    "# # Perform the aggregation\n",
    "# result = list(withStation.aggregate(pipeline))\n",
    "\n",
    "# # Assign to a variable\n",
    "# Top10Routes = db['Top10Routes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
