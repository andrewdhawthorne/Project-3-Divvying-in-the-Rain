{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Divvy Bike Data: \n",
    "\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202201-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202202-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202203-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202204-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202205-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202206-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202207-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202208-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202209-divvy-publictripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202210-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202211-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline  202212-divvy-tripdata.csv<br>\n",
    "\n",
    "### Import Weather Data: \n",
    "mongoimport --type csv -d chicago_bikes -c weather_daily --headerline weather_daily.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient, UpdateOne\n",
    "import json\n",
    "\n",
    "# Adding for query to find top ten stations \n",
    "#from pymongo.collection import Collection\n",
    "#from pymongo.aggregation import Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of MongoClient\n",
    "mongo = MongoClient(port=27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'autosaurus', 'chicago_bikes', 'classDB', 'config', 'epa', 'fruits_db', 'local', 'met', 'travel_db', 'uk_food']\n"
     ]
    }
   ],
   "source": [
    "# confirm that our new database was created\n",
    "print(mongo.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the database to a variable name\n",
    "db = mongo.chicago_bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weather_daily', 'withStationName', 'withoutStationName', 'divvy_ridedata', 'Top10StartStations', 'divvy_ridedata_merged']\n"
     ]
    }
   ],
   "source": [
    "# review the collections in our new database\n",
    "print(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('64e404c003505f880eefb45e'), 'ride_id': 'A6CF8980A652D272', 'rideable_type': 'electric_bike', 'started_at': '2022-01-10 08:41:56', 'ended_at': '2022-01-10 08:46:17', 'start_station_name': 'Glenwood Ave & Touhy Ave', 'start_station_id': 525, 'end_station_name': 'Clark St & Touhy Ave', 'end_station_id': 'RP-007', 'start_lat': 42.012763, 'start_lng': -87.6659675, 'end_lat': 42.01256011541, 'end_lng': -87.6743671152, 'member_casual': 'casual', 'started_at_date': '2022-01-10', 'started_at_time': '08:41:56', 'ended_at_date': '2022-01-10', 'ended_at_time': '08:46:17'}\n"
     ]
    }
   ],
   "source": [
    "# review a document in the customer_list collection\n",
    "print(db.divvy_ridedata.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy_rides = db['divvy_ridedata']\n",
    "weather_daily = db['weather_daily']\n",
    "withStation = db['withStationName']\n",
    "withoutStation = db['withoutStationName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(divvy_rides.count_documents({}))\n",
    "print(weather_daily.count_documents({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = divvy_rides.find({})\n",
    "bulk_updates = []\n",
    "\n",
    "for document in documents:\n",
    "    original_value = document[\"started_at\"]\n",
    "    parts = original_value.split(\" \")\n",
    "    date_part = parts[0]\n",
    "    time_part = parts[1]\n",
    "    bulk_updates.append(\n",
    "        pymongo.UpdateOne(\n",
    "            {\"_id\": document[\"_id\"]},\n",
    "            {\n",
    "                \"$set\": {\n",
    "                    \"started_at_date\": date_part,\n",
    "                    \"started_at_time\": time_part\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Execute bulk write operations\n",
    "divvy_rides.bulk_write(bulk_updates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = divvy_rides.find({})\n",
    "bulk_updates = []\n",
    "\n",
    "for document in documents:\n",
    "    original_value = document[\"ended_at\"]\n",
    "    parts = original_value.split(\" \")\n",
    "    date_part = parts[0]\n",
    "    time_part = parts[1]\n",
    "    bulk_updates.append(\n",
    "        pymongo.UpdateOne(\n",
    "            {\"_id\": document[\"_id\"]},\n",
    "            {\n",
    "                \"$set\": {\n",
    "                    \"ended_at_date\": date_part,\n",
    "                    \"ended_at_time\": time_part\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Execute bulk write operations\n",
    "divvy_rides.bulk_write(bulk_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.divvy_ridedata.find_one())\n",
    "print(db.weather_daily.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'date_1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divvy_rides.create_index([(\"started_at_date\", 1)])\n",
    "weather_daily.create_index([(\"date\", 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        '$lookup': {\n",
    "            'from': 'weather_daily',\n",
    "            'localField': 'started_at_date',\n",
    "            'foreignField': 'date',\n",
    "            'as': 'weather_data'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$unwind': {\n",
    "            'path': '$weather_data',\n",
    "            'preserveNullAndEmptyArrays': True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$merge': {\n",
    "            'into': 'divvy_ridedata_merged',  # Replace with your new collection name\n",
    "            'whenMatched': 'merge',  # Merge documents with matching _id fields\n",
    "            'whenNotMatched': 'insert'  # Insert documents that don't match\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "divvy_rides.aggregate(pipeline)\n",
    "print(\"Update completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('64e4eab4a682807a5695d165'),\n",
       " 'end_lat': 42.01256011541,\n",
       " 'end_lng': -87.6743671152,\n",
       " 'end_station_id': 'RP-007',\n",
       " 'end_station_name': 'Clark St & Touhy Ave',\n",
       " 'ended_at': '2022-01-13 12:02:44',\n",
       " 'ended_at_date': '2022-01-13',\n",
       " 'ended_at_time': '12:02:44',\n",
       " 'member_casual': 'casual',\n",
       " 'ride_id': 'C2F7DD78E82EC875',\n",
       " 'rideable_type': 'electric_bike',\n",
       " 'start_lat': 42.0128005,\n",
       " 'start_lng': -87.665906,\n",
       " 'start_station_id': 525,\n",
       " 'start_station_name': 'Glenwood Ave & Touhy Ave',\n",
       " 'started_at': '2022-01-13 11:59:47',\n",
       " 'started_at_date': '2022-01-13',\n",
       " 'started_at_time': '11:59:47',\n",
       " 'weather_data': {'_id': ObjectId('64e4ebecb589d1838b565c57'),\n",
       "  'date': '2022-01-13',\n",
       "  'cloud_cover': 75.0,\n",
       "  'precipitation': 0.0,\n",
       "  'min_temp': 30.72,\n",
       "  'max_temp': 39.83,\n",
       "  'morning_temp': 35.49,\n",
       "  'afternoon_temp': 30.72,\n",
       "  'evening_temp': 34.38,\n",
       "  'night_temp': 39.22,\n",
       "  'max_windspeed': 8.01}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divvy_ridedata_merged = db['divvy_ridedata_merged']\n",
    "divvy_ridedata_merged.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weather_daily', 'withStationName', 'withoutStationName', 'divvy_ridedata', 'Top10StartStations', 'divvy_ridedata_merged']\n"
     ]
    }
   ],
   "source": [
    "# review the collections in our new database\n",
    "print(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to create a collection that contains start and end station names\n",
    "pipeline = [\n",
    "         {\"$match\": {\"start_station_name\": {\"$exists\": True, \"$ne\": \"\"}, \n",
    "                     \"end_station_name\":{\"$exists\": True, \"$ne\": \"\"}}},\n",
    "\n",
    "         {\"$out\": \"withStationName\"}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(divvy_ridedata_merged.aggregate(pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to make sure that collections is updated\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there are any documents without start or end station names\n",
    "print(db.withStationName.find_one({\"start_station_name\":\"\"}))\n",
    "print(db.withStationName.find_one({\"end_station_name\":\"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to create a collection that doesn't contain start and end station names\n",
    "pipeline = [\n",
    "         {\"$match\": {\"start_station_name\": {\"$exists\": True, \"$eq\": \"\"}, \n",
    "                     \"end_station_name\":{\"$exists\": True, \"$eq\": \"\"}}},\n",
    "\n",
    "         {\"$out\": \"withoutStationName\"}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(divvy_ridedata_merged.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there are any documents without start or end station names\n",
    "print(db.withoutStationName.find_one({\"start_station_name\":{\"$ne\":\"\"}}))\n",
    "print(db.withoutStationName.find_one({\"end_station_name\":{\"$ne\":\"\"}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to find top ten start stations \n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$start_station_name\",\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"latitude\": {\"$first\": \"$end_lat\"},\n",
    "            \"longitude\": {\"$first\": \"$end_lng\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"count\": -1}\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 10\n",
    "    },\n",
    "    {   \"$out\": \"Top10StartStations\"\n",
    "}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(withStation.aggregate(pipeline))\n",
    "\n",
    "# Assign collection to a variable\n",
    "Top10StartStations = db['Top10StartStations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Top10Routes',\n",
       " 'weather_daily',\n",
       " 'withStationName',\n",
       " 'withoutStationName',\n",
       " 'Top10EndStations',\n",
       " 'divvy_ridedata',\n",
       " 'Top10StartStations',\n",
       " 'divvy_ridedata_merged']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see that the collection was added\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'Streeter Dr & Grand Ave',\n",
       " 'count': 71269,\n",
       " 'latitude': 41.880958,\n",
       " 'longitude': -87.616743}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top10StartStations.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to find top ten end stations \n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$end_station_name\",\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"latitude\": {\"$first\": \"$end_lat\"},\n",
    "            \"longitude\": {\"$first\": \"$end_lng\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"count\": -1}\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 10\n",
    "    },\n",
    "    {   \"$out\": \"Top10EndStations\"\n",
    "}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(withStation.aggregate(pipeline))\n",
    "\n",
    "# Assign to a variable\n",
    "Top10EndStations = db['Top10EndStations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline query to find the top ten bike routes (by start and end station)\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": { \"Start Station\": \"$start_station_name\", \"End Station\": \"$end_station_name\"},\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"latitude\": {\"$first\": \"$end_lat\"},\n",
    "            \"longitude\": {\"$first\": \"$end_lng\"}\n",
    "        }\n",
    "    },\n",
    "    {\"$sort\": {\"count\": -1}\n",
    "},\n",
    "    {\n",
    "        \"$limit\": 10\n",
    "},\n",
    "    {   \"$out\": \"Top10Routes\"\n",
    "}\n",
    "]\n",
    "# Perform the aggregation\n",
    "result = list(withStation.aggregate(pipeline))\n",
    "\n",
    "# Assign to a variable\n",
    "Top10Routes = db['Top10Routes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline query to find the top ten bike routes (by start and end lat/lon)\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": { \"Start Station\": \"$start_station_name\", \"End Station\": \"$end_station_name\"},\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"latitude\": {\"$first\": \"$end_lat\"},\n",
    "            \"longitude\": {\"$first\": \"$end_lng\"}\n",
    "        }\n",
    "    },\n",
    "    {\"$sort\": {\"count\": -1}\n",
    "},\n",
    "    {\n",
    "        \"$limit\": 10\n",
    "},\n",
    "    {   \"$out\": \"Top10Routes\"\n",
    "}\n",
    "]\n",
    "# Perform the aggregation\n",
    "result = list(withStation.aggregate(pipeline))\n",
    "\n",
    "# Assign to a variable\n",
    "Top10Routes = db['Top10Routes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
