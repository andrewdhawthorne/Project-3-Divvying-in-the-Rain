{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Divvy Bike Data: \n",
    "\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202201-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202202-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202203-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202204-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202205-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202206-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202207-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202208-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202209-divvy-publictripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202210-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline 202211-divvy-tripdata.csv<br>\n",
    "mongoimport --type csv -d chicago_bikes -c divvy_ridedata --headerline  202212-divvy-tripdata.csv<br>\n",
    "\n",
    "### Import Weather Data: \n",
    "mongoimport --type csv -d chicago_bikes -c weather_daily --headerline weather_daily.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient, UpdateOne\n",
    "import json\n",
    "\n",
    "# Adding for query to find top ten stations \n",
    "#from pymongo.collection import Collection\n",
    "#from pymongo.aggregation import Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of MongoClient\n",
    "mongo = MongoClient(port=27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'autosaurus', 'chicago_bikes', 'classDB', 'config', 'epa', 'fruits_db', 'gardenDB', 'local', 'met', 'travel_db', 'uk_food']\n"
     ]
    }
   ],
   "source": [
    "# confirm that our new database was created\n",
    "print(mongo.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the database to a variable name\n",
    "db = mongo.chicago_bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weather_daily', 'divvy_ridedata', 'divvy_ridedata_merged']\n"
     ]
    }
   ],
   "source": [
    "# review the collections in our new database\n",
    "print(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review a document in the customer_list collection\n",
    "print(db.divvy_ridedata.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy_rides = db['divvy_ridedata']\n",
    "weather_daily = db['weather_daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(divvy_rides.count_documents({}))\n",
    "print(weather_daily.count_documents({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = divvy_rides.find({})\n",
    "bulk_updates = []\n",
    "\n",
    "for document in documents:\n",
    "    original_value = document[\"started_at\"]\n",
    "    parts = original_value.split(\" \")\n",
    "    date_part = parts[0]\n",
    "    time_part = parts[1]\n",
    "    bulk_updates.append(\n",
    "        pymongo.UpdateOne(\n",
    "            {\"_id\": document[\"_id\"]},\n",
    "            {\n",
    "                \"$set\": {\n",
    "                    \"started_at_date\": date_part,\n",
    "                    \"started_at_time\": time_part\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Execute bulk write operations\n",
    "divvy_rides.bulk_write(bulk_updates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = divvy_rides.find({})\n",
    "bulk_updates = []\n",
    "\n",
    "for document in documents:\n",
    "    original_value = document[\"ended_at\"]\n",
    "    parts = original_value.split(\" \")\n",
    "    date_part = parts[0]\n",
    "    time_part = parts[1]\n",
    "    bulk_updates.append(\n",
    "        pymongo.UpdateOne(\n",
    "            {\"_id\": document[\"_id\"]},\n",
    "            {\n",
    "                \"$set\": {\n",
    "                    \"ended_at_date\": date_part,\n",
    "                    \"ended_at_time\": time_part\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Execute bulk write operations\n",
    "divvy_rides.bulk_write(bulk_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.divvy_ridedata.find_one())\n",
    "print(db.weather_daily.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy_rides.create_index([(\"started_at_date\", 1)])\n",
    "weather_daily.create_index([(\"date\", 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        '$lookup': {\n",
    "            'from': 'weather_daily',\n",
    "            'localField': 'started_at_date',\n",
    "            'foreignField': 'date',\n",
    "            'as': 'weather_data'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$unwind': {\n",
    "            'path': '$weather_data',\n",
    "            'preserveNullAndEmptyArrays': True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$merge': {\n",
    "            'into': 'divvy_ridedata_merged',  # Replace with your new collection name\n",
    "            'whenMatched': 'merge',  # Merge documents with matching _id fields\n",
    "            'whenNotMatched': 'insert'  # Insert documents that don't match\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "divvy_rides.aggregate(pipeline)\n",
    "print(\"Update completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('64e404c003505f880eefb45e'),\n",
       " 'end_lat': 42.01256011541,\n",
       " 'end_lng': -87.6743671152,\n",
       " 'end_station_id': 'RP-007',\n",
       " 'end_station_name': 'Clark St & Touhy Ave',\n",
       " 'ended_at': '2022-01-10 08:46:17',\n",
       " 'ended_at_date': '2022-01-10',\n",
       " 'ended_at_time': '08:46:17',\n",
       " 'member_casual': 'casual',\n",
       " 'ride_id': 'A6CF8980A652D272',\n",
       " 'rideable_type': 'electric_bike',\n",
       " 'start_lat': 42.012763,\n",
       " 'start_lng': -87.6659675,\n",
       " 'start_station_id': 525,\n",
       " 'start_station_name': 'Glenwood Ave & Touhy Ave',\n",
       " 'started_at': '2022-01-10 08:41:56',\n",
       " 'started_at_date': '2022-01-10',\n",
       " 'started_at_time': '08:41:56',\n",
       " 'weather_data': {'_id': ObjectId('64e413e0cf380c0c3c2737eb'),\n",
       "  'date': '2022-01-10',\n",
       "  'cloud_cover': 17.0,\n",
       "  'precipitation': 0.24,\n",
       "  'min_temp': 9.5,\n",
       "  'max_temp': 20.84,\n",
       "  'morning_temp': 13.69,\n",
       "  'afternoon_temp': 9.73,\n",
       "  'evening_temp': 14.0,\n",
       "  'night_temp': 20.75,\n",
       "  'max_windspeed': 16.35}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divvy_ridedata_merged = db['divvy_ridedata_merged']\n",
    "divvy_ridedata_merged.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review the collections in our new database\n",
    "print(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy_rides_withStation = divvy_ridedata_merged.find({ \n",
    "    \"start_station_name\": { \"$exists\": True },\n",
    "    \"$expr\": { \"$gt\": [{ \"$strLenCP\": \"$start_station_name\" }, 0] } \n",
    "})\n",
    "divvy_rides_withStation.aggregate([{\"$out\": \"withStation\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to create a collection that contains start and end station names\n",
    "pipeline = [\n",
    "         {\"$match\": {\"start_station_name\": {\"$exists\": True, \"$ne\": \"\"}, \n",
    "                     \"end_station_name\":{\"$exists\": True, \"$ne\": \"\"}}},\n",
    "\n",
    "         {\"$out\": \"withStationName\"}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(divvy_ridedata_merged.aggregate(pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather_daily', 'withStationName', 'divvy_ridedata', 'divvy_ridedata_merged']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to make sure that collections is updated\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#check if there are any documents without start or end station names\n",
    "print(db.withStationName.find_one({\"start_station_name\":\"\"}))\n",
    "print(db.withStationName.find_one({\"end_station_name\":\"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation pipeline to create a collection that doesn't start and end station names\n",
    "pipeline = [\n",
    "         {\"$match\": {\"start_station_name\": {\"$exists\": True, \"$eq\": \"\"}, \n",
    "                     \"end_station_name\":{\"$exists\": True, \"$eq\": \"\"}}},\n",
    "\n",
    "         {\"$out\": \"withoutStationName\"}\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(divvy_ridedata_merged.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather_daily',\n",
       " 'withStationName',\n",
       " 'withoutStationName',\n",
       " 'divvy_ridedata',\n",
       " 'divvy_ridedata_merged']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#check if there are any documents without start or end station names\n",
    "print(db.withoutStationName.find_one({\"start_station_name\":{\"$ne\":\"\"}}))\n",
    "print(db.withoutStationName.find_one({\"end_station_name\":{\"$ne\":\"\"}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '', 'count': 892742, 'latitude': 41.9, 'longitude': -87.64}\n",
      "{'_id': 'Streeter Dr & Grand Ave', 'count': 75382, 'latitude': 41.892278, 'longitude': -87.612043}\n",
      "{'_id': 'DuSable Lake Shore Dr & North Blvd', 'count': 42141, 'latitude': 41.911722, 'longitude': -87.626804}\n",
      "{'_id': 'Michigan Ave & Oak St', 'count': 40127, 'latitude': 41.90096039, 'longitude': -87.62377664}\n",
      "{'_id': 'DuSable Lake Shore Dr & Monroe St', 'count': 40125, 'latitude': 41.880958, 'longitude': -87.616743}\n",
      "{'_id': 'Wells St & Concord Ln', 'count': 37421, 'latitude': 41.912133, 'longitude': -87.634656}\n",
      "{'_id': 'Millennium Park', 'count': 35234, 'latitude': 41.8810317, 'longitude': -87.62408432}\n",
      "{'_id': 'Clark St & Elm St', 'count': 34490, 'latitude': 41.902973, 'longitude': -87.63128}\n",
      "{'_id': 'Theater on the Lake', 'count': 32988, 'latitude': 41.926277, 'longitude': -87.630834}\n",
      "{'_id': 'Kingsbury St & Kinzie St', 'count': 32380, 'latitude': 41.88917683258, 'longitude': -87.6385057718}\n",
      "{'_id': 'Wells St & Elm St', 'count': 30338, 'latitude': 41.903222, 'longitude': -87.634324}\n"
     ]
    }
   ],
   "source": [
    "# Use aggregation pipeline to find top ten end stations \n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$end_station_name\",\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"latitude\": {\"$first\": \"$end_lat\"},\n",
    "            \"longitude\": {\"$first\": \"$end_lng\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"count\": -1}\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 11\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform the aggregation\n",
    "result = list(divvy_ridedata_merged.aggregate(pipeline))\n",
    "\n",
    "# Print the result\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline query to find the top ten bike routes (by start and end station)\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": { \"Start Station\": \"$start_station_name\", \"End Station\": \"$end_station_name\"},\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"latitude\": {\"$first\": \"$end_lat\"},\n",
    "            \"longitude\": {\"$first\": \"$end_lng\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"count\": -1}\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 11\n",
    "    }\n",
    "]\n",
    "# Perform the aggregation\n",
    "result = list(divvy_ridedata_merged.aggregate(pipeline))\n",
    "# Print the result\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
